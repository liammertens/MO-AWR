{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122035,"status":"ok","timestamp":1746090871564,"user":{"displayName":"Liam Mertens","userId":"17654526473594897979"},"user_tz":-120},"id":"z_jVbzLTRMFu","outputId":"6b4eec16-fc75-42ad-c566-1d59efa0160c","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mo-gymnasium\n","  Downloading mo_gymnasium-1.3.1-py3-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from mo-gymnasium) (1.1.1)\n","Collecting numpy<2.0,>=1.21.0 (from mo-gymnasium)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from mo-gymnasium) (2.6.1)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from mo-gymnasium) (1.15.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->mo-gymnasium) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->mo-gymnasium) (4.13.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->mo-gymnasium) (0.0.4)\n","Downloading mo_gymnasium-1.3.1-py3-none-any.whl (479 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m479.6/479.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, mo-gymnasium\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed mo-gymnasium-1.3.1 numpy-1.26.4\n","Collecting git+https://github.com/LucasAlegre/morl-baselines.git\n","  Cloning https://github.com/LucasAlegre/morl-baselines.git to /tmp/pip-req-build-ihzl5mbj\n","  Running command git clone --filter=blob:none --quiet https://github.com/LucasAlegre/morl-baselines.git /tmp/pip-req-build-ihzl5mbj\n","  Resolved https://github.com/LucasAlegre/morl-baselines.git to commit 92572aa5ee13e98b9e080f64df8e29602dba4f69\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: mo-gymnasium>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (1.3.1)\n","Requirement already satisfied: gymnasium>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (1.1.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (1.26.4)\n","Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (2.6.0+cu124)\n","Requirement already satisfied: pygame>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (2.6.1)\n","Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (1.15.2)\n","Collecting pymoo>=0.6.0 (from morl-baselines==1.1.0)\n","  Downloading pymoo-0.6.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: wandb>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (0.19.10)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (2.37.0)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (1.0.3)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (0.13.2)\n","Requirement already satisfied: cvxpy in /usr/local/lib/python3.11/dist-packages (from morl-baselines==1.1.0) (1.6.5)\n","Collecting fire (from morl-baselines==1.1.0)\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->morl-baselines==1.1.0) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->morl-baselines==1.1.0) (4.13.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0->morl-baselines==1.1.0) (0.0.4)\n","Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from pymoo>=0.6.0->morl-baselines==1.1.0) (3.10.0)\n","Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.11/dist-packages (from pymoo>=0.6.0->morl-baselines==1.1.0) (1.7.0)\n","Collecting cma==3.2.2 (from pymoo>=0.6.0->morl-baselines==1.1.0)\n","  Downloading cma-3.2.2-py2.py3-none-any.whl.metadata (8.0 kB)\n","Collecting alive-progress (from pymoo>=0.6.0->morl-baselines==1.1.0)\n","  Downloading alive_progress-3.2.0-py3-none-any.whl.metadata (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill (from pymoo>=0.6.0->morl-baselines==1.1.0)\n","  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from pymoo>=0.6.0->morl-baselines==1.1.0) (1.2.18)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->morl-baselines==1.1.0) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->morl-baselines==1.1.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->morl-baselines==1.1.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->morl-baselines==1.1.0) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->morl-baselines==1.1.0) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->morl-baselines==1.1.0) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->morl-baselines==1.1.0) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.12.0->morl-baselines==1.1.0)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->morl-baselines==1.1.0) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.12.0->morl-baselines==1.1.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.12.0->morl-baselines==1.1.0) (1.3.0)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (8.1.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (3.1.44)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (4.3.7)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (5.29.4)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (5.9.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (2.11.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (6.0.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (2.32.3)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (2.27.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (1.3.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.14.0->morl-baselines==1.1.0) (75.2.0)\n","Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from cvxpy->morl-baselines==1.1.0) (1.0.3)\n","Requirement already satisfied: clarabel>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from cvxpy->morl-baselines==1.1.0) (0.10.0)\n","Requirement already satisfied: scs>=3.2.4.post1 in /usr/local/lib/python3.11/dist-packages (from cvxpy->morl-baselines==1.1.0) (3.2.7.post2)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->morl-baselines==1.1.0) (3.0.1)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio->morl-baselines==1.1.0) (11.2.1)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy->morl-baselines==1.1.0) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy->morl-baselines==1.1.0) (4.67.1)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy->morl-baselines==1.1.0) (0.1.11)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy->morl-baselines==1.1.0) (0.6.0)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn->morl-baselines==1.1.0) (2.2.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.14.0->morl-baselines==1.1.0) (1.17.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.14.0->morl-baselines==1.1.0) (4.0.12)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0->morl-baselines==1.1.0) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0->morl-baselines==1.1.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0->morl-baselines==1.1.0) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0->morl-baselines==1.1.0) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0->morl-baselines==1.1.0) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0->morl-baselines==1.1.0) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0->morl-baselines==1.1.0) (2.9.0.post0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->cvxpy->morl-baselines==1.1.0) (1.4.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->morl-baselines==1.1.0) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->morl-baselines==1.1.0) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.14.0->morl-baselines==1.1.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.14.0->morl-baselines==1.1.0) (2.33.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb>=0.14.0->morl-baselines==1.1.0) (0.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.14.0->morl-baselines==1.1.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.14.0->morl-baselines==1.1.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.14.0->morl-baselines==1.1.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb>=0.14.0->morl-baselines==1.1.0) (2025.1.31)\n","Collecting about-time==4.2.1 (from alive-progress->pymoo>=0.6.0->morl-baselines==1.1.0)\n","  Downloading about_time-4.2.1-py3-none-any.whl.metadata (13 kB)\n","Collecting grapheme==0.6.0 (from alive-progress->pymoo>=0.6.0->morl-baselines==1.1.0)\n","  Downloading grapheme-0.6.0.tar.gz (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->pymoo>=0.6.0->morl-baselines==1.1.0) (1.17.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.12.0->morl-baselines==1.1.0) (3.0.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.14.0->morl-baselines==1.1.0) (5.0.2)\n","Downloading pymoo-0.6.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cma-3.2.2-py2.py3-none-any.whl (249 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/249.1 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alive_progress-3.2.0-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading about_time-4.2.1-py3-none-any.whl (13 kB)\n","Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: morl-baselines, fire, grapheme\n","  Building wheel for morl-baselines (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for morl-baselines: filename=morl_baselines-1.1.0-py3-none-any.whl size=129966 sha256=b0422d0fd000b6250c41ae1f7146e582061dc4d214eb09a373d384ca5a6f8628\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-8omwp018/wheels/b0/cd/e2/da3228d6d2ffb2f6c95ad330c10a9c17b7c8d89014cf9cf21a\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=345369fcacb5ccb24c2afaecba11de320e8feaf0a6408a685f98511859259f67\n","  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n","  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for grapheme: filename=grapheme-0.6.0-py3-none-any.whl size=210082 sha256=76f10ed8798b21b09dc71ad3ef65b30b4d2d2cfb68bf312761e74738201642f3\n","  Stored in directory: /root/.cache/pip/wheels/ee/3b/0b/1b865800e916d671a24028d884698674138632a83fdfad4926\n","Successfully built morl-baselines fire grapheme\n","Installing collected packages: grapheme, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fire, dill, cma, about-time, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alive-progress, pymoo, nvidia-cusolver-cu12, morl-baselines\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed about-time-4.2.1 alive-progress-3.2.0 cma-3.2.2 dill-0.4.0 fire-0.7.0 grapheme-0.6.0 morl-baselines-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pymoo-0.6.1.3\n"]}],"source":["!pip install mo-gymnasium\n","!pip install git+https://github.com/LucasAlegre/morl-baselines.git"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":10613,"status":"ok","timestamp":1746090925324,"user":{"displayName":"Liam Mertens","userId":"17654526473594897979"},"user_tz":-120},"id":"PXKlO1PuRTEG"},"outputs":[],"source":["import gymnasium as gym\n","import mo_gymnasium as mo_gym\n","import numpy as np\n","from MO_AWR import MO_AWR\n","#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zMHHo5c7LLJ","outputId":"a633c21f-ba5b-43d2-843c-067c217248af","executionInfo":{"status":"ok","timestamp":1746104242026,"user_tz":-120,"elapsed":13302438,"user":{"displayName":"Liam Mertens","userId":"17654526473594897979"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gymnasium/spaces/box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n","  gym.logger.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaminguitvoer ingekort tot de laatste 5000 regels.\u001b[0m\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 801002 \t return [ 20.356 -15.093], ([0.591 0.564]), new return [ 21.072 -14.627] \t value loss 3.880E-02 \t policy loss 1.430E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 20.779, -16.209]) 15.8125]\n"," [array([ 17.037, -11.026]) 10.8125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 18.965, -14.627]) 14.25]\n"," [array([ 17.701, -12.06 ]) 11.875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([14.17 , -7.306]) 7.0625]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.411, -2.407]) 2.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 801791 \t return [ 2.905 -1.605], ([3.536 0.971]), new return [12.505 -1.683] \t value loss 2.964E-02 \t policy loss 1.578E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.95 , -2.783]) 2.75]\n"," [array([ 2.411, -2.407]) 2.375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 18.965, -14.627]) 14.25]\n"," [array([15.86 , -9.361]) 9.125]\n"," [array([ 17.701, -12.06 ]) 11.875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 17.037, -11.026]) 10.8125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 802855 \t return [ 19.603 -12.894], ([1.118 1.302]), new return [ 22.727 -13.603] \t value loss 2.643E-02 \t policy loss 4.491E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.411, -2.407]) 2.375]\n"," [array([14.724, -7.644]) 7.375]\n"," [array([15.86 , -9.361]) 9.125]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 18.965, -14.627]) 14.25]\n"," [array([13.193, -6.789]) 6.625]\n"," [array([ 17.701, -12.06 ]) 11.875]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 804036 \t return [ 20.372 -17.669], ([1.236 0.952]), new return [ 23.465 -19.108] \t value loss 3.099E-02 \t policy loss 7.260E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.796, -7.161]) 6.9375]\n"," [array([13.193, -6.789]) 6.625]\n"," [array([ 17.646, -11.987]) 11.8125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 18.965, -14.627]) 14.25]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.411, -2.407]) 2.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 805102 \t return [ 16.892 -13.096], ([0.926 1.138]), new return [ 20.292 -15.257] \t value loss 3.086E-02 \t policy loss 6.912E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.342, -7.613]) 7.375]\n"," [array([ 17.646, -11.987]) 11.8125]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([ 18.965, -14.627]) 14.25]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.411, -2.407]) 2.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([15.594, -8.756]) 8.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 806269 \t return [ 19.582 -16.994], ([1.348 1.496]), new return [ 23.018 -17.725] \t value loss 3.925E-02 \t policy loss 5.794E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.828, -1.993]) 2.0]\n"," [array([14.342, -7.613]) 7.375]\n"," [array([13.768, -6.959]) 6.75]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.411, -2.407]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 807044 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [9.787 3.007] \t value loss 2.604E-02 \t policy loss 6.567E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.087, -8.661]) 8.5]\n"," [array([13.835, -6.921]) 6.6875]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([15.491, -9.083]) 8.875]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([ 2.411, -2.407]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 807847 \t return [ 5.18  -2.218], ([3.971 1.08 ]), new return [13.835  0.084] \t value loss 3.457E-02 \t policy loss 3.843E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 3.393, -2.685]) 2.625]\n"," [array([15.805, -9.329]) 9.1875]\n"," [array([14.94 , -8.364]) 8.1875]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([13.835, -6.921]) 6.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 808841 \t return [ 17.473 -10.027], ([1.307 1.61 ]), new return [ 25.148 -13.134] \t value loss 3.853E-02 \t policy loss 3.607E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.835, -6.921]) 6.6875]\n"," [array([ 0.828, -1.993]) 2.0]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([15.805, -9.329]) 9.1875]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 3.393, -2.685]) 2.625]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 809622 \t return [ 1.638 -1.255], ([2.541 0.692]), new return [11.006 -1.129] \t value loss 2.745E-02 \t policy loss 4.167E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.971, -6.854]) 6.75]\n"," [array([15.805, -9.329]) 9.1875]\n"," [array([ 0.828, -1.993]) 2.0]\n"," [array([12.505, -6.006]) 5.8125]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 3.393, -2.685]) 2.625]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 810598 \t return [16.819 -9.386], ([0.101 0.202]), new return [ 22.35  -11.133] \t value loss 2.228E-02 \t policy loss 2.572E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.805, -9.329]) 9.1875]\n"," [array([14.992, -8.138]) 7.9375]\n"," [array([12.361, -5.937]) 5.75]\n"," [array([ 0.828, -1.993]) 2.0]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 3.393, -2.685]) 2.625]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 811528 \t return [15.063 -7.477], ([0.462 0.4  ]), new return [20.918 -8.138] \t value loss 2.841E-02 \t policy loss 2.256E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.965, -6.592]) 6.375]\n"," [array([15.166, -8.126]) 7.875]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 0.828, -1.993]) 2.0]\n"," [array([12.549, -5.834]) 5.625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 3.393, -2.685]) 2.625]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 812329 \t return [ 4.841 -2.119], ([3.979 1.075]), new return [12.965  0.915] \t value loss 3.711E-02 \t policy loss 2.870E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.828, -1.993]) 2.0]\n"," [array([14.417, -7.52 ]) 7.3125]\n"," [array([11.947, -5.449]) 5.25]\n"," [array([ 2.465, -2.425]) 2.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([15.166, -8.126]) 7.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 813553 \t return [ 21.42  -19.052], ([0.777 1.229]), new return [ 25.911 -21.206] \t value loss 3.814E-02 \t policy loss 3.785E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.417, -7.52 ]) 7.3125]\n"," [array([11.947, -5.449]) 5.25]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([16.034, -9.334]) 9.125]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([15.166, -8.126]) 7.875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.465, -2.425]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 814412 \t return [10.851 -4.619], ([1.614 1.002]), new return [14.417 -4.693] \t value loss 5.026E-02 \t policy loss 7.149E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.828, -1.993]) 2.0]\n"," [array([16.034, -9.334]) 9.125]\n"," [array([11.947, -5.449]) 5.25]\n"," [array([15.166, -8.126]) 7.875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 815668 \t return [ 20.566 -20.508], ([0.889 0.887]), new return [ 25.026 -23.129] \t value loss 2.922E-02 \t policy loss 4.777E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.765, -10.402]) 10.1875]\n"," [array([15.166, -8.126]) 7.875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([14.007, -7.62 ]) 7.4375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([11.947, -5.449]) 5.25]\n"," [array([13.135, -6.467]) 6.25]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 816491 \t return [ 8.401 -3.11 ], ([1.572 0.431]), new return [15.166 -0.877] \t value loss 3.021E-02 \t policy loss 6.876E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.812, -1.988]) 2.0]\n"," [array([12.762, -6.174]) 6.0]\n"," [array([14.007, -7.62 ]) 7.4375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([15.166, -8.126]) 7.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 817718 \t return [ 23.23  -18.613], ([0.534 0.447]), new return [ 30.061 -21.206] \t value loss 2.823E-02 \t policy loss 4.196E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([ 16.765, -10.402]) 10.1875]\n"," [array([12.932, -6.855]) 6.75]\n"," [array([15.882, -9.442]) 9.375]\n"," [array([12.762, -6.174]) 6.0]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 818617 \t return [12.941 -6.243], ([1.26  1.053]), new return [13.725 -6.174] \t value loss 5.305E-02 \t policy loss 6.630E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.92 , -2.541]) 2.5]\n"," [array([15.882, -9.442]) 9.375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([12.422, -6.039]) 5.875]\n"," [array([13.825, -6.971]) 6.75]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([14.706, -8.239]) 8.125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 819567 \t return [15.839 -8.282], ([0. 0.]), new return [20.879 -9.442] \t value loss 3.025E-02 \t policy loss 1.033E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([13.623, -6.939]) 6.75]\n"," [array([ 2.92 , -2.541]) 2.5]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([12.422, -6.039]) 5.875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([15.882, -9.442]) 9.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 820358 \t return [ 3.245 -1.698], ([3.711 1.017]), new return [13.623 -1.166] \t value loss 2.832E-02 \t policy loss 3.839E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([14.966, -8.526]) 8.4375]\n"," [array([ 2.92 , -2.541]) 2.5]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([12.422, -6.039]) 5.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([15.882, -9.442]) 9.375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 821602 \t return [ 20.266 -20.116], ([0.591 0.673]), new return [ 22.727 -20.972] \t value loss 2.257E-02 \t policy loss 3.753E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.92 , -2.541]) 2.5]\n"," [array([ 18.606, -13.081]) 12.9375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 16.878, -10.65 ]) 10.4375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([14.966, -8.526]) 8.4375]\n"," [array([12.422, -6.039]) 5.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 822377 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 4.44  -0.287] \t value loss 5.090E-02 \t policy loss 6.533E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.606, -13.081]) 12.9375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 16.878, -10.65 ]) 10.4375]\n"," [array([12.422, -6.039]) 5.875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([14.851, -8.522]) 8.375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([12.782, -6.44 ]) 6.3125]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 823611 \t return [ 20.009 -19.65 ], ([1.471 1.373]), new return [ 23.172 -20.939] \t value loss 2.681E-02 \t policy loss 4.304E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.088, -9.319]) 9.1875]\n"," [array([ 18.606, -13.081]) 12.9375]\n"," [array([12.422, -6.039]) 5.875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([14.575, -8.384]) 8.125]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([12.782, -6.44 ]) 6.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 824390 \t return [ 1.304 -1.166], ([2.049 0.564]), new return [ 8.335 -2.569] \t value loss 4.818E-02 \t policy loss 3.888E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.897, -6.048]) 5.8125]\n"," [array([14.013, -7.862]) 7.8125]\n"," [array([ 18.606, -13.081]) 12.9375]\n"," [array([13.686, -6.96 ]) 6.75]\n"," [array([12.422, -6.039]) 5.875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 825165 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 3.599 -1.   ] \t value loss 2.437E-02 \t policy loss 4.243E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.125, -8.906]) 8.8125]\n"," [array([ 18.606, -13.081]) 12.9375]\n"," [array([13.686, -6.96 ]) 6.75]\n"," [array([12.422, -6.039]) 5.875]\n"," [array([ 16.451, -10.685]) 10.6875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 825940 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 8.335 -0.124] \t value loss 2.465E-02 \t policy loss 3.259E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.467, -2.415]) 2.375]\n"," [array([13.686, -6.96 ]) 6.75]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.606, -13.081]) 12.9375]\n"," [array([12.638, -5.887]) 5.6875]\n"," [array([ 16.451, -10.685]) 10.6875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 826715 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 7.767 -2.423] \t value loss 2.546E-02 \t policy loss 5.741E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.467, -2.415]) 2.375]\n"," [array([15.488, -8.83 ]) 8.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.606, -13.081]) 12.9375]\n"," [array([ 16.753, -10.56 ]) 10.5625]\n"," [array([12.638, -5.887]) 5.6875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 827843 \t return [ 18.313 -15.691], ([1.749 1.433]), new return [ 21.23  -17.725] \t value loss 2.396E-02 \t policy loss 5.565E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 15.958, -10.284]) 10.0625]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.606, -13.081]) 12.9375]\n"," [array([13.531, -7.259]) 7.0625]\n"," [array([ 16.753, -10.56 ]) 10.5625]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([12.638, -5.887]) 5.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 828922 \t return [ 19.658 -13.561], ([0.973 1.241]), new return [ 21.144 -13.081] \t value loss 3.726E-02 \t policy loss 9.257E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.662, -9.05 ]) 8.8125]\n"," [array([13.531, -7.259]) 7.0625]\n"," [array([ 16.753, -10.56 ]) 10.5625]\n"," [array([15.114, -8.189]) 8.0]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([12.638, -5.887]) 5.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 830030 \t return [ 20.764 -14.577], ([0.172 0.669]), new return [ 24.45 -15.66] \t value loss 3.395E-02 \t policy loss 6.658E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.6  , -7.717]) 7.5]\n"," [array([13.531, -7.259]) 7.0625]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([13.392, -7.095]) 6.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([12.638, -5.887]) 5.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 831144 \t return [ 19.917 -15.145], ([1.303 1.37 ]), new return [ 20.881 -15.66 ] \t value loss 4.176E-02 \t policy loss 6.575E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.392, -7.095]) 6.9375]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([ 15.717, -10.097]) 9.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([14.6  , -7.717]) 7.5]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([12.638, -5.887]) 5.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 832345 \t return [ 20.861 -18.005], ([0.186 0.771]), new return [ 25.604 -18.723] \t value loss 2.745E-02 \t policy loss 7.988E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.555, -9.076]) 8.875]\n"," [array([14.6  , -7.717]) 7.5]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([13.392, -7.095]) 6.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([12.638, -5.887]) 5.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 833120 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 3.912 -1.   ] \t value loss 3.981E-02 \t policy loss 1.005E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.357, -8.624]) 8.5]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([14.6  , -7.717]) 7.5]\n"," [array([13.392, -7.095]) 6.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([12.638, -5.887]) 5.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 834038 \t return [14.23  -7.042], ([2.822 1.313]), new return [20.205 -7.717] \t value loss 3.385E-02 \t policy loss 4.624E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.812, -1.988]) 2.0]\n"," [array([13.763, -7.049]) 6.875]\n"," [array([15.357, -8.624]) 8.5]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([12.638, -5.887]) 5.6875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 834849 \t return [ 6.489 -2.583], ([3.61  0.987]), new return [15.357 -0.914] \t value loss 2.842E-02 \t policy loss 5.945E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.763, -6.154]) 5.9375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([15.357, -8.624]) 8.5]\n"," [array([14.249, -7.887]) 7.75]\n"," [array([13.763, -7.049]) 6.875]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 835724 \t return [11.699 -5.255], ([0.000e+00 9.537e-07]), new return [12.763 -5.439] \t value loss 2.592E-02 \t policy loss 5.978E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.639, -10.356]) 10.1875]\n"," [array([ 16.321, -10.012]) 9.875]\n"," [array([14.499, -7.773]) 7.5625]\n"," [array([12.763, -6.154]) 5.9375]\n"," [array([15.357, -8.624]) 8.5]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 836767 \t return [ 17.553 -12.207], ([1.425 1.25 ]), new return [ 20.292 -13.634] \t value loss 3.133E-02 \t policy loss 4.385E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.639, -10.356]) 10.1875]\n"," [array([ 16.321, -10.012]) 9.875]\n"," [array([14.499, -7.773]) 7.5625]\n"," [array([13.605, -7.131]) 6.9375]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([15.357, -8.624]) 8.5]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 837878 \t return [ 19.797 -14.78 ], ([1.579 1.978]), new return [ 22.551 -15.66 ] \t value loss 3.543E-02 \t policy loss 6.068E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([15.357, -8.624]) 8.5]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([ 16.321, -10.012]) 9.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([13.282, -6.97 ]) 6.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 838705 \t return [ 8.74 -3.25], ([0.694 0.415]), new return [16.639 -4.799] \t value loss 5.532E-02 \t policy loss 1.045E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([ 16.321, -10.012]) 9.875]\n"," [array([14.071, -8.336]) 8.3125]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([15.357, -8.624]) 8.5]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 839480 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [9.787 3.133] \t value loss 2.495E-02 \t policy loss 4.905E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.357, -8.624]) 8.5]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([ 16.321, -10.012]) 9.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([14.446, -8.059]) 7.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([12.862, -6.101]) 5.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 840271 \t return [ 3.217 -1.687], ([3.669 1.002]), new return [15.058 -3.941] \t value loss 2.363E-02 \t policy loss 3.162E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.639, -10.356]) 10.1875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 16.321, -10.012]) 9.875]\n"," [array([15.357, -8.624]) 8.5]\n"," [array([12.862, -6.101]) 5.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([14.446, -8.059]) 7.875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 841536 \t return [ 21.336 -20.643], ([0.595 0.55 ]), new return [ 25.887 -23.129] \t value loss 2.680E-02 \t policy loss 5.225E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([16.027, -9.704]) 9.5625]\n"," [array([15.357, -8.624]) 8.5]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([14.162, -8.015]) 7.8125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([12.862, -6.101]) 5.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 842637 \t return [ 20.473 -14.414], ([0.632 0.317]), new return [ 23.508 -15.66 ] \t value loss 4.285E-02 \t policy loss 4.285E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.357, -8.624]) 8.5]\n"," [array([ 0.812, -1.988]) 2.0]\n"," [array([13.705, -7.667]) 7.5]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([12.862, -6.101]) 5.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 843412 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [0.7   2.745] \t value loss 2.376E-02 \t policy loss 2.897E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.741, -8.409]) 8.1875]\n"," [array([15.558, -9.42 ]) 9.3125]\n"," [array([13.829, -7.323]) 7.1875]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([12.862, -6.101]) 5.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 844333 \t return [13.9   -7.121], ([0.673 0.569]), new return [13.829 -6.936] \t value loss 2.809E-02 \t policy loss 4.373E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.816, -9.404]) 9.25]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([13.829, -7.323]) 7.1875]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([12.862, -6.101]) 5.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 845436 \t return [ 20.625 -14.39 ], ([0.081 0.297]), new return [ 23.818 -15.66 ] \t value loss 2.790E-02 \t policy loss 3.895E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.896, -9.275]) 9.1875]\n"," [array([12.862, -6.101]) 5.875]\n"," [array([12.04 , -5.624]) 5.4375]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([13.829, -7.323]) 7.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 846217 \t return [ 1.016 -1.25 ], ([1.406 0.533]), new return [ 4.44  -2.694] \t value loss 2.485E-02 \t policy loss 6.935E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.729, -8.895]) 8.8125]\n"," [array([14.71 , -8.135]) 7.9375]\n"," [array([13.829, -7.323]) 7.1875]\n"," [array([ 18.677, -12.824]) 12.8125]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 846992 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [11.006  1.536] \t value loss 3.206E-02 \t policy loss 2.833E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.109, -11.109]) 11.0]\n"," [array([ 18.677, -12.824]) 12.8125]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([15.262, -9.42 ]) 9.3125]\n"," [array([ 16.639, -10.356]) 10.1875]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 847942 \t return [15.642 -8.346], ([0.003 0.   ]), new return [ 20.405 -10.356] \t value loss 2.206E-02 \t policy loss 1.730E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.109, -11.109]) 11.0]\n"," [array([ 16.073, -10.021]) 9.9375]\n"," [array([ 18.677, -12.824]) 12.8125]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([14.017, -7.58 ]) 7.375]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 848859 \t return [14.183 -7.039], ([1.661 1.136]), new return [17.109 -6.495] \t value loss 2.322E-02 \t policy loss 1.397E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.66 , -6.384]) 6.1875]\n"," [array([ 18.677, -12.824]) 12.8125]\n"," [array([16.268, -9.957]) 9.75]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([14.944, -8.821]) 8.6875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 850132 \t return [ 20.982 -21.081], ([0.519 0.549]), new return [ 23.172 -21.606] \t value loss 2.792E-02 \t policy loss 6.538E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([16.268, -9.957]) 9.75]\n"," [array([13.651, -7.335]) 7.125]\n"," [array([ 18.677, -12.824]) 12.8125]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 851082 \t return [15.496 -8.345], ([1.907e-06 9.537e-07]), new return [16.268 -7.787] \t value loss 3.990E-02 \t policy loss 4.302E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.677, -12.824]) 12.8125]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([14.782, -8.671]) 8.5]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([16.276, -9.567]) 9.375]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 851873 \t return [ 3.134 -1.673], ([3.549 0.981]), new return [ 9.381 -3.014] \t value loss 2.312E-02 \t policy loss 3.871E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.414, -9.24 ]) 9.0625]\n"," [array([ 18.677, -12.824]) 12.8125]\n"," [array([16.276, -9.567]) 9.375]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 852824 \t return [15.275 -8.459], ([0.196 0.202]), new return [16.397 -9.24 ] \t value loss 3.436E-02 \t policy loss 3.150E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.684, -10.815]) 10.6875]\n"," [array([ 18.677, -12.824]) 12.8125]\n"," [array([16.276, -9.567]) 9.375]\n"," [array([13.114, -6.567]) 6.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 853943 \t return [ 20.378 -15.262], ([0.156 1.004]), new return [ 21.486 -15.66 ] \t value loss 3.047E-02 \t policy loss 3.374E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([16.276, -9.567]) 9.375]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([13.611, -7.445]) 7.25]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([15.234, -9.476]) 9.3125]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 854718 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 4.44  -0.901] \t value loss 3.675E-02 \t policy loss 4.576E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.828, -1.993]) 2.0]\n"," [array([12.859, -6.993]) 6.875]\n"," [array([16.276, -9.567]) 9.375]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 855493 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [11.006  2.699] \t value loss 2.781E-02 \t policy loss 8.435E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.684, -10.815]) 10.6875]\n"," [array([13.39 , -7.716]) 7.625]\n"," [array([12.546, -5.784]) 5.5625]\n"," [array([16.276, -9.567]) 9.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.006, -4.851]) 4.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([14.776, -8.658]) 8.5]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 856334 \t return [ 9.438 -3.845], ([3.087 1.304]), new return [18.829 -5.784] \t value loss 3.123E-02 \t policy loss 5.300E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.546, -5.784]) 5.5625]\n"," [array([11.958, -5.611]) 5.375]\n"," [array([14.848, -8.663]) 8.5]\n"," [array([14.601, -7.437]) 7.1875]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([16.276, -9.567]) 9.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 857284 \t return [15.182 -8.35 ], ([0.008 0.002]), new return [16.276 -9.393] \t value loss 2.566E-02 \t policy loss 4.139E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.848, -8.663]) 8.5]\n"," [array([15.159, -9.315]) 9.1875]\n"," [array([13.472, -6.948]) 6.8125]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([14.601, -7.437]) 7.1875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.958, -5.611]) 5.375]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 858571 \t return [ 22.139 -21.698], ([0.485 0.769]), new return [ 24.794 -23.129] \t value loss 2.504E-02 \t policy loss 2.850E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([15.358, -8.595]) 8.375]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([14.601, -7.437]) 7.1875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([13.472, -6.948]) 6.8125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([11.958, -5.611]) 5.375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 859484 \t return [14.32  -6.857], ([1.147 0.859]), new return [21.545 -7.437] \t value loss 4.351E-02 \t policy loss 8.465E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.962, -8.545]) 8.375]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([14.601, -7.437]) 7.1875]\n"," [array([13.472, -6.948]) 6.8125]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([11.958, -5.611]) 5.375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 860259 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 2.482 -1.637] \t value loss 2.794E-02 \t policy loss 3.771E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.601, -7.437]) 7.1875]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([14.962, -8.545]) 8.375]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([12.993, -6.486]) 6.3125]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.958, -5.611]) 5.375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 861502 \t return [ 23.291 -19.668], ([0.428 2.124]), new return [ 27.536 -21.206] \t value loss 2.787E-02 \t policy loss 3.077E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.684, -10.815]) 10.6875]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([16.036, -9.408]) 9.25]\n"," [array([14.601, -7.437]) 7.1875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([12.993, -6.486]) 6.3125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.958, -5.611]) 5.375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 862456 \t return [15.887 -8.512], ([0.378 0.363]), new return [20.292 -9.805] \t value loss 1.591E-01 \t policy loss 7.488E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([16.036, -9.408]) 9.25]\n"," [array([15.035, -8.869]) 8.75]\n"," [array([14.601, -7.437]) 7.1875]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([13.284, -6.443]) 6.1875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.958, -5.611]) 5.375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 863590 \t return [ 20.014 -15.748], ([1.281 1.319]), new return [ 22.727 -16.401] \t value loss 2.433E-02 \t policy loss 2.991E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([16.036, -9.408]) 9.25]\n"," [array([14.601, -7.437]) 7.1875]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([13.284, -6.443]) 6.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.958, -5.611]) 5.375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 864411 \t return [ 7.791 -2.942], ([2.091 0.573]), new return [11.993 -3.941] \t value loss 2.769E-02 \t policy loss 4.597E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.425, -9.38 ]) 9.1875]\n"," [array([13.693, -6.988]) 6.8125]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([16.036, -9.408]) 9.25]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 865386 \t return [16.632 -9.318], ([0. 0.]), new return [ 21.343 -11.401] \t value loss 2.593E-02 \t policy loss 3.203E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.571, -8.367]) 8.1875]\n"," [array([15.655, -9.17 ]) 9.0]\n"," [array([16.036, -9.408]) 9.25]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.693, -6.988]) 6.8125]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 866295 \t return [13.566 -6.646], ([1.19  0.967]), new return [14.571 -5.979] \t value loss 2.557E-02 \t policy loss 5.462E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.828, -1.993]) 2.0]\n"," [array([16.036, -9.408]) 9.25]\n"," [array([13.693, -6.988]) 6.8125]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([12.23 , -5.971]) 5.8125]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 867216 \t return [14.548 -7.153], ([0.718 0.554]), new return [17.848 -6.076] \t value loss 2.578E-02 \t policy loss 5.174E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.828, -1.993]) 2.0]\n"," [array([13.095, -6.54 ]) 6.3125]\n"," [array([14.073, -7.449]) 7.25]\n"," [array([16.036, -9.408]) 9.25]\n"," [array([ 16.684, -10.815]) 10.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 868622 \t return [ 21.483 -25.914], ([0.593 0.562]), new return [ 25.952 -27.591] \t value loss 2.327E-02 \t policy loss 3.253E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.095, -6.54 ]) 6.3125]\n"," [array([ 16.688, -10.504]) 10.4375]\n"," [array([12.183, -5.786]) 5.5625]\n"," [array([16.036, -9.408]) 9.25]\n"," [array([14.824, -7.848]) 7.625]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 869633 \t return [ 16.466 -10.813], ([0.686 0.856]), new return [ 18.892 -12.813] \t value loss 3.651E-02 \t policy loss 1.915E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.044, -7.754]) 7.5625]\n"," [array([12.183, -5.786]) 5.5625]\n"," [array([16.036, -9.408]) 9.25]\n"," [array([ 16.688, -10.504]) 10.4375]\n"," [array([14.824, -7.848]) 7.625]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 870408 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 7.108 -1.   ] \t value loss 3.266E-02 \t policy loss 4.619E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.446, -6.224]) 6.0625]\n"," [array([13.435, -7.331]) 7.125]\n"," [array([14.824, -7.848]) 7.625]\n"," [array([ 16.688, -10.504]) 10.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([16.036, -9.408]) 9.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 871183 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [2.482 1.025] \t value loss 2.542E-02 \t policy loss 5.919E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.824, -7.848]) 7.625]\n"," [array([13.932, -7.655]) 7.5]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([12.446, -6.224]) 6.0625]\n"," [array([ 16.688, -10.504]) 10.4375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 871958 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 5.285 -2.423] \t value loss 2.550E-02 \t policy loss 7.464E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.688, -10.504]) 10.4375]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([14.087, -7.571]) 7.375]\n"," [array([ 16.266, -10.367]) 10.3125]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([14.824, -7.848]) 7.625]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 872733 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 6.698 -1.   ] \t value loss 2.433E-02 \t policy loss 4.154E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.812, -1.988]) 2.0]\n"," [array([ 16.266, -10.367]) 10.3125]\n"," [array([ 16.688, -10.504]) 10.4375]\n"," [array([15.515, -9.034]) 8.9375]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 873508 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 2.482 -1.012] \t value loss 2.558E-02 \t policy loss 3.724E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.266, -10.367]) 10.3125]\n"," [array([ 16.688, -10.504]) 10.4375]\n"," [array([14.189, -8.116]) 7.9375]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([15.515, -9.034]) 8.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 874477 \t return [16.315 -9.116], ([0.437 0.426]), new return [ 19.48  -10.367] \t value loss 2.367E-02 \t policy loss 5.643E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.746, -6.702]) 6.4375]\n"," [array([14.409, -7.816]) 7.625]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 16.754, -10.328]) 10.1875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([15.515, -9.034]) 8.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 875466 \t return [16.991 -9.985], ([0.945 1.168]), new return [ 22.726 -13.134] \t value loss 2.865E-02 \t policy loss 4.964E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.746, -6.702]) 6.4375]\n"," [array([ 16.754, -10.328]) 10.1875]\n"," [array([14.409, -7.816]) 7.625]\n"," [array([15.515, -9.034]) 8.9375]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 876443 \t return [16.611 -9.339], ([0.37  0.607]), new return [ 21.634 -10.328] \t value loss 2.894E-02 \t policy loss 5.299E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.844, -1.997]) 2.0]\n"," [array([13.746, -6.702]) 6.4375]\n"," [array([15.677, -9.559]) 9.4375]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 16.754, -10.328]) 10.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 877270 \t return [ 8.858 -3.283], ([0.712 0.417]), new return [17.848 -3.257] \t value loss 2.864E-02 \t policy loss 4.111E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.746, -6.702]) 6.4375]\n"," [array([15.553, -8.965]) 8.75]\n"," [array([ 16.754, -10.328]) 10.1875]\n"," [array([14.331, -8.25 ]) 8.0625]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 878045 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [8.335 1.397] \t value loss 2.359E-02 \t policy loss 3.876E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.574, -5.793]) 5.5625]\n"," [array([13.746, -6.702]) 6.4375]\n"," [array([15.933, -9.389]) 9.125]\n"," [array([15.553, -8.965]) 8.75]\n"," [array([ 16.754, -10.328]) 10.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 879024 \t return [16.795 -9.501], ([0.196 0.527]), new return [ 22.087 -11.401] \t value loss 2.552E-02 \t policy loss 3.718E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([14.55 , -7.799]) 7.5625]\n"," [array([ 3.437, -2.675]) 2.625]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([13.746, -6.702]) 6.4375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 879845 \t return [ 7.776 -2.95 ], ([2.087 0.575]), new return [11.658 -3.941] \t value loss 2.706E-02 \t policy loss 3.091E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.677, -8.685]) 8.5]\n"," [array([15.559, -9.471]) 9.375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([13.746, -6.702]) 6.4375]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 15.951, -10.063]) 9.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 880820 \t return [16.578 -9.397], ([0.012 0.003]), new return [ 20.912 -11.927] \t value loss 2.568E-02 \t policy loss 3.963E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([13.746, -6.702]) 6.4375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 17.507, -11.331]) 11.25]\n"," [array([ 15.951, -10.063]) 9.9375]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 881795 \t return [16.504 -9.389], ([5.722e-06 0.000e+00]), new return [ 20.292 -11.559] \t value loss 2.764E-02 \t policy loss 3.758E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.106, -10.285]) 10.125]\n"," [array([14.238, -7.345]) 7.125]\n"," [array([ 17.119, -11.038]) 10.9375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([13.746, -6.702]) 6.4375]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 882720 \t return [14.635 -7.34 ], ([4.768e-06 1.431e-06]), new return [17.119 -6.747] \t value loss 2.176E-02 \t policy loss 2.793E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.561, -8.724]) 8.5]\n"," [array([ 17.119, -11.038]) 10.9375]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 16.106, -10.285]) 10.125]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 883984 \t return [ 20.72  -20.853], ([1.038 0.937]), new return [ 24.662 -23.129] \t value loss 3.004E-02 \t policy loss 2.360E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([16.202, -9.932]) 9.75]\n"," [array([14.492, -7.941]) 7.8125]\n"," [array([ 18.892, -13.134]) 12.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([13.227, -7.029]) 6.8125]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 885275 \t return [ 21.622 -21.62 ], ([0.586 0.752]), new return [ 25.473 -23.129] \t value loss 4.080E-02 \t policy loss 5.039E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.838, -9.215]) 9.0]\n"," [array([16.202, -9.932]) 9.75]\n"," [array([ 17.848, -11.401]) 11.1875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 16.895, -10.763]) 10.625]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 886144 \t return [11.41  -5.021], ([2.29 0.92]), new return [16.269 -5.793] \t value loss 4.029E-02 \t policy loss 1.486E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.895, -10.763]) 10.625]\n"," [array([13.223, -7.039]) 6.875]\n"," [array([16.202, -9.932]) 9.75]\n"," [array([ 2.962, -2.793]) 2.75]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([12.574, -5.793]) 5.5625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 886919 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 8.335 -1.404] \t value loss 2.446E-02 \t policy loss 5.240E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.58 , -9.915]) 9.8125]\n"," [array([13.223, -7.039]) 6.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([14.142, -7.629]) 7.4375]\n"," [array([15.027, -8.273]) 8.0625]\n"," [array([ 16.895, -10.763]) 10.625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 887744 \t return [ 8.573 -3.179], ([9.537e-07 0.000e+00]), new return [15.027 -3.931] \t value loss 2.395E-02 \t policy loss 6.068E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.223, -7.039]) 6.875]\n"," [array([15.027, -8.273]) 8.0625]\n"," [array([14.225, -7.345]) 7.125]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 16.895, -10.763]) 10.625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 888565 \t return [ 7.545 -2.937], ([2.609 0.827]), new return [10.76  -3.941] \t value loss 2.723E-02 \t policy loss 4.093E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.027, -8.273]) 8.0625]\n"," [array([ 16.989, -11.092]) 11.0]\n"," [array([14.225, -7.345]) 7.125]\n"," [array([16.409, -9.458]) 9.25]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 889488 \t return [14.772 -7.22 ], ([0.526 0.397]), new return [18.917 -5.989] \t value loss 2.561E-02 \t policy loss 3.767E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.804, -1.985]) 2.0]\n"," [array([16.409, -9.458]) 9.25]\n"," [array([14.225, -7.345]) 7.125]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 16.989, -11.092]) 11.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 890415 \t return [14.227 -7.436], ([0.298 0.286]), new return [14.304 -7.345] \t value loss 3.194E-02 \t policy loss 3.969E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 3.395, -2.904]) 2.875]\n"," [array([15.017, -8.591]) 8.4375]\n"," [array([16.409, -9.458]) 9.25]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 16.989, -11.092]) 11.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 891194 \t return [ 1.307 -1.168], ([2.059 0.571]), new return [ 8.539 -2.423] \t value loss 2.378E-02 \t policy loss 4.747E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.546, -6.889]) 6.6875]\n"," [array([14.425, -7.862]) 7.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([15.018, -8.538]) 8.375]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 16.989, -11.092]) 11.0]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 892515 \t return [ 21.501 -22.617], ([0.545 0.632]), new return [ 27.017 -25.422] \t value loss 2.889E-02 \t policy loss 3.622E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.105, -10.904]) 10.8125]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([15.113, -8.339]) 8.1875]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([15.817, -9.726]) 9.5625]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 893432 \t return [14.126 -6.986], ([0.953 0.761]), new return [15.817 -6.092] \t value loss 3.559E-02 \t policy loss 3.982E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([16.399, -9.567]) 9.375]\n"," [array([14.306, -8.058]) 7.9375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 17.105, -10.904]) 10.8125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 894407 \t return [16.721 -9.365], ([0.005 0.004]), new return [ 20.912 -10.747] \t value loss 2.630E-02 \t policy loss 3.222E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 20.547, -17.607]) 17.5625]\n"," [array([13.849, -7.186]) 6.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([16.399, -9.567]) 9.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 17.105, -10.904]) 10.8125]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 895506 \t return [ 20.905 -14.064], ([0.175 0.307]), new return [ 26.619 -15.66 ] \t value loss 2.270E-02 \t policy loss 3.538E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 20.547, -17.607]) 17.5625]\n"," [array([16.399, -9.567]) 9.375]\n"," [array([14.311, -8.248]) 8.0625]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([13.849, -7.186]) 6.9375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 896472 \t return [16.407 -8.967], ([0.495 0.477]), new return [20.193 -9.567] \t value loss 2.961E-02 \t policy loss 3.437E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.804, -1.985]) 2.0]\n"," [array([13.849, -7.186]) 6.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([16.399, -9.567]) 9.375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 897247 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [11.472 -0.213] \t value loss 3.036E-02 \t policy loss 6.811E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.849, -7.186]) 6.9375]\n"," [array([ 0.804, -1.985]) 2.0]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 16.63 , -10.367]) 10.125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 898262 \t return [ 17.506 -10.866], ([0.642 1.132]), new return [ 23.974 -12.109] \t value loss 1.733E-02 \t policy loss 1.020E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([16.139, -9.161]) 8.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([14.941, -7.998]) 7.75]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 16.63 , -10.367]) 10.125]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 899234 \t return [16.103 -9.282], ([0.363 0.442]), new return [16.139 -8.611] \t value loss 2.636E-02 \t policy loss 4.840E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.544, -8.683]) 8.5]\n"," [array([ 17.524, -11.407]) 11.25]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([14.019, -7.284]) 7.0625]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 900009 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [4.44  2.607] \t value loss 2.528E-02 \t policy loss 6.443E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 20.547, -17.607]) 17.5625]\n"," [array([14.404, -8.058]) 7.9375]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([15.605, -8.944]) 8.8125]\n"," [array([ 16.779, -11.026]) 10.9375]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 901027 \t return [ 16.587 -11.185], ([0.246 1.459]), new return [ 18.917 -11.576] \t value loss 2.356E-02 \t policy loss 5.776E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.038, -10.9  ]) 10.75]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 16.373, -10.259]) 10.0625]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([14.874, -7.987]) 7.8125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 902019 \t return [ 15.823 -10.032], ([0.251 0.741]), new return [ 17.038 -10.546] \t value loss 5.537E-02 \t policy loss 1.183E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.083, -7.283]) 7.0625]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 17.038, -10.9  ]) 10.75]\n"," [array([14.874, -7.987]) 7.8125]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 903026 \t return [ 16.355 -10.723], ([0.416 1.264]), new return [ 17.716 -10.9  ] \t value loss 3.437E-02 \t policy loss 6.436E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([14.874, -7.987]) 7.8125]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.912, -17.725]) 17.375]\n"," [array([ 17.038, -10.9  ]) 10.75]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 904303 \t return [ 22.521 -20.909], ([0.885 0.753]), new return [ 27.514 -23.129] \t value loss 2.963E-02 \t policy loss 2.141E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.469, -8.898]) 8.75]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([13.742, -6.968]) 6.75]\n"," [array([15.808, -9.613]) 9.4375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([14.874, -7.987]) 7.8125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 905078 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [11.472  2.887] \t value loss 4.921E-02 \t policy loss 1.009E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.576, -8.736]) 8.5625]\n"," [array([ 3.433, -2.924]) 2.875]\n"," [array([14.874, -7.987]) 7.8125]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([13.084, -6.193]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 16.603, -10.295]) 10.1875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 905903 \t return [ 8.288 -3.132], ([1.688 0.604]), new return [12.715 -3.941] \t value loss 2.951E-02 \t policy loss 4.490E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.804, -1.985]) 2.0]\n"," [array([15.815, -9.443]) 9.3125]\n"," [array([12.085, -5.811]) 5.625]\n"," [array([14.874, -7.987]) 7.8125]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 16.603, -10.295]) 10.1875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 906931 \t return [ 17.996 -11.379], ([1.375 1.717]), new return [ 25.072 -13.454] \t value loss 2.267E-02 \t policy loss 2.797E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([15.388, -9.143]) 9.0]\n"," [array([ 17.32 , -11.252]) 11.1875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([12.085, -5.811]) 5.625]\n"," [array([14.874, -7.987]) 7.8125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 907706 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [2.482 2.33 ] \t value loss 3.109E-02 \t policy loss 5.517E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.224, -12.109]) 12.0]\n"," [array([ 16.557, -10.041]) 9.875]\n"," [array([ 3.47 , -2.691]) 2.625]\n"," [array([ 17.32 , -11.252]) 11.1875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([14.189, -7.562]) 7.375]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([12.085, -5.811]) 5.625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 908577 \t return [11.479 -5.068], ([0.913 0.576]), new return [12.779 -5.084] \t value loss 2.621E-02 \t policy loss 3.978E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.458, -6.837]) 6.625]\n"," [array([16.113, -9.46 ]) 9.3125]\n"," [array([ 16.557, -10.041]) 9.875]\n"," [array([15.401, -8.305]) 8.0625]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 17.32 , -11.252]) 11.1875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 909527 \t return [16.13  -8.339], ([0.000e+00 2.861e-06]), new return [22.334 -8.305] \t value loss 2.536E-02 \t policy loss 3.201E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 3.488, -2.933]) 2.875]\n"," [array([ 17.32 , -11.252]) 11.1875]\n"," [array([16.159, -9.193]) 8.9375]\n"," [array([15.125, -7.962]) 7.6875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([13.458, -6.837]) 6.625]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 910392 \t return [11.01  -4.795], ([1.333 0.851]), new return [11.472 -4.356] \t value loss 2.782E-02 \t policy loss 3.429E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 3.488, -2.933]) 2.875]\n"," [array([15.125, -7.962]) 7.6875]\n"," [array([16.499, -9.702]) 9.4375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 17.32 , -11.252]) 11.1875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([13.458, -6.837]) 6.625]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 911185 \t return [ 3.507 -1.768], ([3.742 1.024]), new return [11.472 -2.087] \t value loss 2.859E-02 \t policy loss 3.334E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.125, -7.962]) 7.6875]\n"," [array([ 3.488, -2.933]) 2.875]\n"," [array([14.214, -7.29 ]) 7.0625]\n"," [array([ 17.32 , -11.252]) 11.1875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.458, -6.837]) 6.625]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 912544 \t return [ 21.89  -24.577], ([0.807 0.976]), new return [ 24.1   -25.422] \t value loss 2.728E-02 \t policy loss 1.414E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.546, -10.308]) 10.1875]\n"," [array([ 17.516, -11.235]) 11.0]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([16.396, -9.579]) 9.375]\n"," [array([15.125, -7.962]) 7.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.458, -6.837]) 6.625]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 913319 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [2.482 3.895] \t value loss 3.613E-02 \t policy loss 6.024E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.359, -7.905]) 7.75]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([15.837, -8.773]) 8.5625]\n"," [array([ 16.847, -10.044]) 9.8125]\n"," [array([ 17.516, -11.235]) 11.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([13.458, -6.837]) 6.625]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 914094 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 2.726 -1.   ] \t value loss 2.950E-02 \t policy loss 4.482E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.847, -10.044]) 9.8125]\n"," [array([ 17.516, -11.235]) 11.0]\n"," [array([15.837, -8.773]) 8.5625]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([14.738, -7.611]) 7.375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([13.458, -6.837]) 6.625]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 915168 \t return [ 19.705 -13.303], ([1.016 0.785]), new return [ 22.498 -13.454] \t value loss 2.960E-02 \t policy loss 5.620E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.379, -8.362]) 8.125]\n"," [array([ 17.516, -11.235]) 11.0]\n"," [array([13.458, -6.837]) 6.625]\n"," [array([14.738, -7.611]) 7.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([13.381, -6.58 ]) 6.3125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 915943 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 2.482 -1.964] \t value loss 3.192E-02 \t policy loss 5.155E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.458, -6.837]) 6.625]\n"," [array([ 16.62, -10.1 ]) 9.9375]\n"," [array([14.738, -7.611]) 7.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 17.516, -11.235]) 11.0]\n"," [array([13.381, -6.58 ]) 6.3125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 917169 \t return [ 20.93  -19.319], ([1.323 0.997]), new return [ 25.426 -21.206] \t value loss 2.355E-02 \t policy loss 4.429E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.224, -12.109]) 12.0]\n"," [array([13.458, -6.837]) 6.625]\n"," [array([ 17.516, -11.235]) 11.0]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 16.62, -10.1 ]) 9.9375]\n"," [array([14.738, -7.611]) 7.375]\n"," [array([13.381, -6.58 ]) 6.3125]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 918044 \t return [12.096 -5.294], ([0.885 0.59 ]), new return [16.62  -4.996] \t value loss 3.015E-02 \t policy loss 4.996E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.999, -7.545]) 7.4375]\n"," [array([ 0.828, -1.993]) 2.0]\n"," [array([15.912, -9.329]) 9.1875]\n"," [array([ 16.62, -10.1 ]) 9.9375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([13.381, -6.58 ]) 6.3125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 918819 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [2.482 0.221] \t value loss 3.051E-02 \t policy loss 4.497E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.224, -12.109]) 12.0]\n"," [array([15.002, -8.407]) 8.1875]\n"," [array([ 17.919, -11.989]) 11.8125]\n"," [array([ 16.788, -10.436]) 10.25]\n"," [array([13.999, -7.545]) 7.4375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 919594 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 5.341 -2.423] \t value loss 2.580E-02 \t policy loss 5.177E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.828, -1.993]) 2.0]\n"," [array([13.99 , -7.441]) 7.3125]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 17.591, -11.127]) 10.9375]\n"," [array([ 16.788, -10.436]) 10.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 920741 \t return [ 21.428 -16.074], ([0.696 1.036]), new return [ 25.469 -17.607] \t value loss 2.503E-02 \t policy loss 2.770E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.281, -8.395]) 8.1875]\n"," [array([13.99 , -7.441]) 7.3125]\n"," [array([15.355, -8.41 ]) 8.1875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 16.501, -10.013]) 9.8125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 921516 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 8.335 -0.903] \t value loss 3.613E-02 \t policy loss 4.268E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.801, -7.761]) 7.5]\n"," [array([15.92, -9.16]) 8.9375]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([13.99 , -7.441]) 7.3125]\n"," [array([ 16.501, -10.013]) 9.8125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 922442 \t return [14.709 -7.405], ([0.222 0.201]), new return [18.432 -7.761] \t value loss 2.333E-02 \t policy loss 3.247E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.99 , -7.441]) 7.3125]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([13.67 , -6.735]) 6.5]\n"," [array([ 16.825, -10.475]) 10.3125]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 923217 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 4.799 -1.   ] \t value loss 2.728E-02 \t policy loss 4.998E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.99 , -7.441]) 7.3125]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([ 17.706, -11.252]) 11.125]\n"," [array([ 16.844, -10.012]) 9.875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 924010 \t return [ 3.435 -1.754], ([3.647 1.006]), new return [ 9.299 -3.014] \t value loss 2.285E-02 \t policy loss 3.250E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.828, -7.397]) 7.25]\n"," [array([ 16.844, -10.012]) 9.875]\n"," [array([14.589, -8.184]) 8.0]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([15.682, -9.44 ]) 9.3125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.917, -13.454]) 13.4375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 925312 \t return [ 21.997 -22.342], ([0.915 1.645]), new return [ 23.596 -22.501] \t value loss 2.564E-02 \t policy loss 3.510E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.117, -8.382]) 8.1875]\n"," [array([14.589, -8.184]) 8.0]\n"," [array([13.828, -7.397]) 7.25]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 16.844, -10.012]) 9.875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 926337 \t return [ 18.497 -11.168], ([1.696 2.078]), new return [ 25.904 -13.354] \t value loss 3.382E-02 \t policy loss 3.955E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.812, -1.988]) 2.0]\n"," [array([16.017, -8.755]) 8.5]\n"," [array([ 17.129, -10.257]) 10.0625]\n"," [array([13.828, -7.397]) 7.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 927512 \t return [ 21.611 -17.458], ([1.449 2.007]), new return [ 23.172 -17.576] \t value loss 2.982E-02 \t policy loss 5.885E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.812, -1.988]) 2.0]\n"," [array([ 17.427, -11.083]) 10.875]\n"," [array([ 18.224, -12.109]) 12.0]\n"," [array([16.017, -8.755]) 8.5]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([13.828, -7.397]) 7.25]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 928855 \t return [ 22.631 -23.208], ([0.62 0.74]), new return [ 28.797 -25.422] \t value loss 3.533E-02 \t policy loss 5.024E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 22.88 , -22.032]) 22.5]\n"," [array([14.979, -8.182]) 7.9375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([13.828, -7.397]) 7.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([16.017, -8.755]) 8.5]\n"," [array([ 17.427, -11.083]) 10.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 930078 \t return [ 23.237 -18.876], ([0.778 0.526]), new return [ 28.664 -21.206] \t value loss 4.025E-02 \t policy loss 4.583E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.812, -1.988]) 2.0]\n"," [array([ 22.88 , -22.032]) 22.5]\n"," [array([14.979, -8.182]) 7.9375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([13.828, -7.397]) 7.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 17.543, -10.891]) 10.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 930897 \t return [ 7.626 -2.909], ([2.557 0.705]), new return [15.951 -5.084] \t value loss 3.347E-02 \t policy loss 3.610E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.396, -5.985]) 5.75]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 16.293, -10.434]) 10.3125]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([15.845, -9.598]) 9.4375]\n"," [array([13.828, -7.397]) 7.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 17.543, -10.891]) 10.6875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 931672 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 0.859 -1.   ] \t value loss 2.851E-02 \t policy loss 4.899E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.786, -10.154]) 10.0]\n"," [array([13.828, -7.397]) 7.25]\n"," [array([12.396, -5.985]) 5.75]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 17.543, -10.891]) 10.6875]\n"," [array([ 18.544, -11.852]) 11.6875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 932647 \t return [16.577 -9.362], ([0.206 0.283]), new return [19.006 -9.74 ] \t value loss 1.760E-02 \t policy loss 4.160E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.786, -10.154]) 10.0]\n"," [array([12.396, -5.985]) 5.75]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([15.152, -8.306]) 8.0625]\n"," [array([ 18.544, -11.852]) 11.6875]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([13.828, -7.397]) 7.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 933622 \t return [16.803 -9.365], ([3.815e-06 9.537e-07]), new return [20.547 -9.931] \t value loss 2.580E-02 \t policy loss 1.883E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([16.251, -9.652]) 9.4375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 16.942, -10.096]) 9.9375]\n"," [array([12.396, -5.985]) 5.75]\n"," [array([ 2.843, -2.771]) 2.75]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([ 18.544, -11.852]) 11.6875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 934810 \t return [ 21.621 -17.744], ([0.975 1.153]), new return [ 24.501 -18.723] \t value loss 2.228E-02 \t policy loss 1.129E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([12.396, -5.985]) 5.75]\n"," [array([ 2.843, -2.771]) 2.75]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([ 2.482, -2.423]) 2.375]\n"," [array([15.173, -8.414]) 8.1875]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([14.546, -8.379]) 8.25]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 935604 \t return [ 0.818 -1.785], ([0.066 0.441]), new return [ 4.673 -2.972] \t value loss 2.366E-02 \t policy loss 4.728E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.002, -6.115]) 5.875]\n"," [array([14.546, -8.379]) 8.25]\n"," [array([12.396, -5.985]) 5.75]\n"," [array([ 2.903, -2.566]) 2.5]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([15.173, -8.414]) 8.1875]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([16.268, -9.914]) 9.75]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 936857 \t return [ 21.059 -20.533], ([0.838 1.564]), new return [ 23.596 -21.566] \t value loss 2.671E-02 \t policy loss 3.490E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.828, -1.993]) 2.0]\n"," [array([ 20.729, -18.509]) 18.0625]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([ 17.346, -11.091]) 10.9375]\n"," [array([14.546, -8.379]) 8.25]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 2.903, -2.566]) 2.5]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 937632 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 4.44  -1.369] \t value loss 2.939E-02 \t policy loss 1.048E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([16.121, -9.253]) 9.0625]\n"," [array([ 20.729, -18.509]) 18.0625]\n"," [array([ 17.184, -10.439]) 10.25]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([14.807, -7.849]) 7.625]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.903, -2.566]) 2.5]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 938710 \t return [ 18.683 -13.682], ([1.671 1.33 ]), new return [ 20.292 -14.334] \t value loss 2.290E-02 \t policy loss 6.922E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([ 20.729, -18.509]) 18.0625]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([14.289, -7.399]) 7.1875]\n"," [array([ 17.831, -11.669]) 11.5625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.903, -2.566]) 2.5]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 939660 \t return [15.829 -8.371], ([3.815e-06 2.861e-06]), new return [19.487 -8.17 ] \t value loss 3.334E-02 \t policy loss 5.861E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.771, -6.704]) 6.4375]\n"," [array([14.792, -7.705]) 7.4375]\n"," [array([ 1.914, -2.278]) 2.25]\n"," [array([ 20.729, -18.509]) 18.0625]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 17.831, -11.669]) 11.5625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 940782 \t return [ 18.502 -15.354], ([1.361 1.037]), new return [ 22.35  -16.858] \t value loss 2.309E-02 \t policy loss 2.681E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.831, -11.669]) 11.5625]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([14.792, -7.705]) 7.4375]\n"," [array([15.624, -8.877]) 8.625]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 1.914, -2.278]) 2.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 941607 \t return [ 8.334 -3.091], ([0.000e+00 2.384e-07]), new return [10.879 -3.941] \t value loss 3.322E-02 \t policy loss 5.357E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.716, -10.551]) 10.375]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([15.732, -9.112]) 8.9375]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([ 17.831, -11.669]) 11.5625]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 1.914, -2.278]) 2.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 942773 \t return [ 21.932 -16.645], ([1.021 0.547]), new return [ 27.928 -18.723] \t value loss 2.121E-02 \t policy loss 7.321E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 3.471, -2.705]) 2.625]\n"," [array([ 18.41 , -12.803]) 12.75]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([ 16.833, -10.194]) 10.0]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([14.851, -8.08 ]) 7.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 943692 \t return [14.345 -7.098], ([0.849 0.673]), new return [17.11  -6.704] \t value loss 2.355E-02 \t policy loss 3.071E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.771, -6.704]) 6.4375]\n"," [array([ 17.575, -11.379]) 11.25]\n"," [array([ 20.292, -15.66 ]) 15.1875]\n"," [array([ 18.41 , -12.803]) 12.75]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 3.471, -2.705]) 2.625]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 944469 \t return [ 1.016 -1.086], ([1.55  0.424]), new return [11.472 -0.219] \t value loss 2.435E-02 \t policy loss 3.847E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.771, -6.704]) 6.4375]\n"," [array([ 0.828, -1.993]) 2.0]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([14.747, -7.644]) 7.375]\n"," [array([16.684, -9.763]) 9.5625]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([15.738, -8.269]) 8.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 3.471, -2.705]) 2.625]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 945292 \t return [ 8.02  -3.008], ([1.494 0.41 ]), new return [10.654 -3.941] \t value loss 2.216E-02 \t policy loss 4.076E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.577, -12.499]) 12.375]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([ 0.836, -1.995]) 2.0]\n"," [array([ 3.421, -2.685]) 2.625]\n"," [array([15.738, -8.269]) 8.0]\n"," [array([14.747, -7.644]) 7.375]\n"," [array([ 19.006, -13.354]) 13.125]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 19.487, -15.35 ]) 15.125]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 946628 \t return [ 20.798 -23.729], ([0.82  0.877]), new return [ 24.159 -25.422] \t value loss 2.293E-02 \t policy loss 3.562E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.102, -10.401]) 10.1875]\n"," [array([ 17.766, -11.272]) 11.0625]\n"," [array([15.738, -8.269]) 8.0]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([ 0.836, -1.995]) 2.0]\n"," [array([14.747, -7.644]) 7.375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 3.421, -2.685]) 2.625]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 947553 \t return [14.39  -7.308], ([9.537e-07 1.431e-06]), new return [15.738 -7.095] \t value loss 2.826E-02 \t policy loss 6.645E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.771, -6.704]) 6.4375]\n"," [array([ 0.844, -1.997]) 2.0]\n"," [array([ 3.37 , -2.668]) 2.625]\n"," [array([16.761, -9.797]) 9.5625]\n"," [array([14.747, -7.644]) 7.375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([15.738, -8.269]) 8.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 17.766, -11.272]) 11.0625]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 948378 \t return [ 8.765 -3.226], ([1.907e-06 4.768e-07]), new return [16.761 -1.766] \t value loss 2.171E-02 \t policy loss 3.242E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.738, -8.269]) 8.0]\n"," [array([ 3.37 , -2.668]) 2.625]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([16.761, -9.797]) 9.5625]\n"," [array([ 17.766, -11.272]) 11.0625]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 18.358, -12.187]) 12.0]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 949646 \t return [ 22.22  -21.325], ([0.721 1.034]), new return [ 23.172 -21.082] \t value loss 2.329E-02 \t policy loss 2.535E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.04 , -10.853]) 10.5625]\n"," [array([ 3.37 , -2.668]) 2.625]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([16.761, -9.797]) 9.5625]\n"," [array([ 18.358, -12.187]) 12.0]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 22.35 , -18.723]) 18.3125]\n"," [array([15.738, -8.269]) 8.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 20.547, -17.607]) 17.5625]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 950894 \t return [ 22.493 -20.428], ([0.883 0.82 ]), new return [ 24.149 -21.206] \t value loss 3.797E-02 \t policy loss 4.486E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 3.37 , -2.668]) 2.625]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 21.205, -18.682]) 18.1875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 18.358, -12.187]) 12.0]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([15.738, -8.269]) 8.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 952159 \t return [ 22.27  -21.186], ([0.738 0.517]), new return [ 23.172 -20.934] \t value loss 2.375E-02 \t policy loss 1.962E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.358, -12.187]) 12.0]\n"," [array([15.738, -8.269]) 8.0]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([ 17.729, -11.87 ]) 11.625]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([16.697, -9.388]) 9.125]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 952934 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 9.787 -0.405] \t value loss 2.820E-02 \t policy loss 8.412E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.358, -12.187]) 12.0]\n"," [array([15.738, -8.269]) 8.0]\n"," [array([ 3.418, -2.681]) 2.625]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([13.771, -6.704]) 6.4375]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([14.477, -8.029]) 7.8125]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 954165 \t return [ 21.891 -19.898], ([0.714 0.68 ]), new return [ 23.465 -20.442] \t value loss 2.422E-02 \t policy loss 4.508E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.738, -8.269]) 8.0]\n"," [array([ 3.418, -2.681]) 2.625]\n"," [array([14.553, -8.017]) 7.75]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 18.358, -12.187]) 12.0]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 954990 \t return [ 8.676 -3.213], ([2.861e-06 7.153e-07]), new return [15.738 -3.131] \t value loss 3.465E-02 \t policy loss 6.568E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.82, -1.99]) 2.0]\n"," [array([16.01 , -9.226]) 9.0]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 16.53 , -10.647]) 10.5]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.358, -12.187]) 12.0]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 955857 \t return [10.99  -4.946], ([3.034 1.164]), new return [13.763 -5.084] \t value loss 2.007E-02 \t policy loss 2.178E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 3.426, -2.688]) 2.625]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([14.003, -7.407]) 7.1875]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 16.53 , -10.647]) 10.5]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.358, -12.187]) 12.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 956708 \t return [ 9.34  -4.225], ([4.935 1.905]), new return [17.538 -6.115] \t value loss 2.029E-02 \t policy loss 6.707E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.066, -6.615]) 6.4375]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([15.144, -8.361]) 8.125]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 16.53 , -10.647]) 10.5]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 18.525, -12.163]) 12.0]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 957483 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [11.472  2.898] \t value loss 2.215E-02 \t policy loss 5.834E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.066, -6.615]) 6.4375]\n"," [array([14.292, -7.86 ]) 7.625]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 16.613, -10.309]) 10.125]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 18.525, -12.163]) 12.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 958304 \t return [ 7.731 -2.925], ([2.073 0.568]), new return [11.472 -4.307] \t value loss 2.691E-02 \t policy loss 3.424E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.155, -8.91 ]) 8.75]\n"," [array([16.34 , -9.297]) 9.0625]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 2.411, -2.41 ]) 2.375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 17.36 , -10.618]) 10.375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 18.525, -12.163]) 12.0]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 959264 \t return [16.498 -8.748], ([0.511 0.476]), new return [ 23.862 -10.618] \t value loss 2.045E-02 \t policy loss 2.385E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.6  , -11.366]) 11.25]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 17.36 , -10.618]) 10.375]\n"," [array([14.453, -7.679]) 7.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 18.525, -12.163]) 12.0]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([16.34 , -9.297]) 9.0625]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 960350 \t return [ 19.333 -13.736], ([1.661 1.858]), new return [ 22.727 -13.788] \t value loss 2.245E-02 \t policy loss 1.740E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.613, -8.63 ]) 8.375]\n"," [array([13.891, -7.13 ]) 6.875]\n"," [array([ 17.36 , -10.618]) 10.375]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 0.812, -1.988]) 2.0]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 3.383, -2.674]) 2.625]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 961384 \t return [ 16.765 -11.833], ([0.085 0.462]), new return [ 21.245 -13.63 ] \t value loss 3.112E-02 \t policy loss 1.099E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 3.383, -2.674]) 2.625]\n"," [array([ 17.36 , -10.618]) 10.375]\n"," [array([ 2.375, -2.397]) 2.375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([13.891, -7.13 ]) 6.875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 17.632, -11.322]) 11.125]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 962301 \t return [14.449 -7.01 ], ([1.817 1.227]), new return [19.661 -6.201] \t value loss 2.600E-02 \t policy loss 5.377E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.306, -12.099]) 11.9375]\n"," [array([ 16.847, -10.35 ]) 10.1875]\n"," [array([ 2.375, -2.397]) 2.375]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([14.159, -7.275]) 7.0625]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([15.746, -8.886]) 8.625]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 963243 \t return [15.739 -8.019], ([0.542 0.469]), new return [22.286 -8.886] \t value loss 2.123E-02 \t policy loss 2.510E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.871, -2.533]) 2.5]\n"," [array([15.007, -7.898]) 7.625]\n"," [array([15.746, -8.886]) 8.625]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([16.885, -9.833]) 9.5625]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 18.306, -12.099]) 11.9375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 964407 \t return [ 21.309 -16.867], ([0.834 0.658]), new return [ 25.553 -18.568] \t value loss 1.971E-02 \t policy loss 2.804E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.306, -12.099]) 11.9375]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([15.746, -8.886]) 8.625]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([14.624, -7.698]) 7.4375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([16.885, -9.833]) 9.5625]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.871, -2.533]) 2.5]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 965390 \t return [16.514 -9.65 ], ([0.138 0.457]), new return [19.661 -9.954] \t value loss 5.753E-02 \t policy loss 5.915E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.871, -2.533]) 2.5]\n"," [array([13.002, -6.115]) 5.875]\n"," [array([13.072, -6.321]) 6.0625]\n"," [array([14.624, -7.698]) 7.4375]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([16.885, -9.833]) 9.5625]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 18.306, -12.099]) 11.9375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 966165 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [0.7   2.005] \t value loss 1.855E-02 \t policy loss 1.946E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.658, -9.044]) 8.8125]\n"," [array([13.072, -6.321]) 6.0625]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 17.178, -10.654]) 10.5625]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 2.871, -2.533]) 2.5]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 18.306, -12.099]) 11.9375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([14.624, -7.698]) 7.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 966940 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [2.871 0.887] \t value loss 2.138E-02 \t policy loss 1.563E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.213, -10.249]) 10.1875]\n"," [array([ 0.828, -1.993]) 2.0]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([13.339, -6.262]) 6.0]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.178, -10.654]) 10.5625]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.871, -2.533]) 2.5]\n"," [array([ 18.306, -12.099]) 11.9375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 967715 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [0.7   1.161] \t value loss 2.061E-02 \t policy loss 3.290E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.871, -2.533]) 2.5]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([16.517, -9.979]) 9.8125]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([15.851, -8.683]) 8.4375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 17.178, -10.654]) 10.5625]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 18.306, -12.099]) 11.9375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 968869 \t return [ 21.535 -16.391], ([0.843 0.45 ]), new return [ 26.514 -18.568] \t value loss 1.800E-02 \t policy loss 3.320E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.812, -1.988]) 2.0]\n"," [array([16.517, -9.979]) 9.8125]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 2.871, -2.533]) 2.5]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 18.306, -12.099]) 11.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([15.851, -8.683]) 8.4375]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 969959 \t return [ 17.905 -14.139], ([1.233 1.203]), new return [ 21.141 -15.107] \t value loss 2.459E-02 \t policy loss 1.566E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.828, -1.993]) 2.0]\n"," [array([ 2.871, -2.533]) 2.5]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([14.943, -8.57 ]) 8.3125]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 18.306, -12.099]) 11.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([13.845, -7.064]) 6.8125]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 970734 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [0.7   7.011] \t value loss 2.822E-02 \t policy loss 6.318E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.845, -7.064]) 6.8125]\n"," [array([ 2.871, -2.533]) 2.5]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 16.969, -10.201]) 9.9375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 18.306, -12.099]) 11.9375]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 971509 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 2.469 -2.011] \t value loss 1.777E-02 \t policy loss 6.097E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.469, -2.423]) 2.375]\n"," [array([ 16.969, -10.201]) 9.9375]\n"," [array([ 17.779, -11.641]) 11.5]\n"," [array([ 18.306, -12.099]) 11.9375]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([13.845, -7.064]) 6.8125]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 972700 \t return [ 22.659 -17.754], ([0.815 0.725]), new return [ 27.477 -19.726] \t value loss 2.132E-02 \t policy loss 6.212E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.484, -12.133]) 12.0]\n"," [array([ 16.786, -10.153]) 10.0]\n"," [array([13.845, -7.064]) 6.8125]\n"," [array([15.623, -9.274]) 9.0625]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 973487 \t return [ 2.634 -1.526], ([3.441 0.937]), new return [13.845  0.976] \t value loss 3.606E-02 \t policy loss 5.084E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.469, -2.423]) 2.375]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 17.143, -10.868]) 10.6875]\n"," [array([14.788, -8.207]) 8.0]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.845, -7.064]) 6.8125]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 974286 \t return [ 4.366 -2.01 ], ([3.816 1.051]), new return [ 9.787 -3.071] \t value loss 1.956E-02 \t policy loss 4.531E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.845, -7.064]) 6.8125]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 17.143, -10.868]) 10.6875]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([15.642, -9.274]) 9.125]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 975157 \t return [11.434 -5.086], ([1.135 0.578]), new return [13.845 -4.843] \t value loss 2.582E-02 \t policy loss 4.698E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.469, -2.423]) 2.375]\n"," [array([ 3.931, -2.83 ]) 2.75]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([16.207, -9.54 ]) 9.3125]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.845, -7.064]) 6.8125]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 975962 \t return [ 5.481 -2.308], ([3.903 1.068]), new return [16.6   -3.941] \t value loss 3.031E-02 \t policy loss 5.609E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.951, -7.926]) 7.8125]\n"," [array([13.845, -7.064]) 6.8125]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([16.207, -9.54 ]) 9.3125]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 977183 \t return [ 22.452 -18.602], ([1.044 1.28 ]), new return [ 26.97  -18.568] \t value loss 2.062E-02 \t policy loss 2.478E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.484, -12.133]) 12.0]\n"," [array([ 17.767, -12.03 ]) 12.0]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 16.963, -10.738]) 10.625]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([15.124, -8.613]) 8.4375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 977958 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [11.472  2.147] \t value loss 4.825E-02 \t policy loss 2.053E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 0.812, -1.988]) 2.0]\n"," [array([ 4.428, -2.954]) 2.875]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([13.672, -6.953]) 6.75]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 979054 \t return [ 18.27  -14.423], ([1.611 0.982]), new return [ 19.661 -14.844] \t value loss 1.871E-02 \t policy loss 8.890E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.158, -8.56 ]) 8.3125]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([16.011, -9.662]) 9.5]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([13.672, -6.953]) 6.75]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 979829 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 7.161 -1.   ] \t value loss 1.955E-02 \t policy loss 4.340E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.696, -8.091]) 7.875]\n"," [array([16.011, -9.662]) 9.5]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 17.049, -11.04 ]) 10.875]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 980606 \t return [ 1.018 -1.085], ([1.559 0.416]), new return [11.472  2.357] \t value loss 2.499E-02 \t policy loss 6.217E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.864, -8.208]) 8.0]\n"," [array([ 17.842, -11.94 ]) 11.8125]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([13.559, -7.071]) 6.9375]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 981615 \t return [ 16.099 -10.811], ([1.149 1.118]), new return [ 18.362 -11.94 ] \t value loss 2.171E-02 \t policy loss 6.543E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.484, -12.133]) 12.0]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([13.559, -7.071]) 6.9375]\n"," [array([ 22.727, -21.206]) 20.9375]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.172, -23.129]) 22.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 17.842, -11.94 ]) 11.8125]\n"," [array([15.997, -9.811]) 9.625]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 982941 \t return [ 23.29  -22.536], ([0.196 0.459]), new return [ 30.404 -25.422] \t value loss 2.640E-02 \t policy loss 1.247E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([13.559, -7.071]) 6.9375]\n"," [array([16.389, -9.962]) 9.8125]\n"," [array([14.112, -7.385]) 7.1875]\n"," [array([ 17.324, -10.989]) 10.875]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 983987 \t return [ 17.444 -12.259], ([0.75  1.192]), new return [ 22.442 -14.229] \t value loss 3.731E-02 \t policy loss 1.400E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([16.225, -9.939]) 9.8125]\n"," [array([13.559, -7.071]) 6.9375]\n"," [array([ 4.416, -2.95 ]) 2.875]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([15.252, -8.638]) 8.375]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 985120 \t return [ 19.293 -15.927], ([1.486 0.922]), new return [ 21.397 -16.869] \t value loss 1.943E-02 \t policy loss 3.845E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.484, -12.133]) 12.0]\n"," [array([16.228, -9.984]) 9.8125]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 17.932, -11.316]) 11.0625]\n"," [array([15.252, -8.638]) 8.375]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([13.559, -7.071]) 6.9375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 986101 \t return [16.135 -9.644], ([0.193 0.438]), new return [ 17.932 -10.902] \t value loss 2.441E-02 \t policy loss 7.483E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.944, -9.27 ]) 9.0625]\n"," [array([ 2.992, -2.794]) 2.75]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([15.191, -8.34 ]) 8.125]\n"," [array([ 19.103, -13.63 ]) 13.4375]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([13.799, -6.963]) 6.75]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 987517 \t return [ 23.168 -25.846], ([0.276 0.621]), new return [ 28.954 -27.591] \t value loss 2.561E-02 \t policy loss 2.430E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 18.484, -12.133]) 12.0]\n"," [array([ 2.992, -2.794]) 2.75]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 17.178, -11.118]) 11.0]\n"," [array([15.191, -8.34 ]) 8.125]\n"," [array([13.799, -6.963]) 6.75]\n"," [array([15.944, -9.27 ]) 9.0625]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 988292 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [2.992 3.228] \t value loss 2.851E-02 \t policy loss 4.052E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.191, -8.34 ]) 8.125]\n"," [array([ 0.804, -1.985]) 2.0]\n"," [array([14.521, -7.745]) 7.5]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([13.799, -6.963]) 6.75]\n"," [array([ 17.178, -11.118]) 11.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 989242 \t return [15.658 -8.348], ([0.001 0.002]), new return [18.484 -8.719] \t value loss 2.421E-02 \t policy loss 4.267E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.178, -11.118]) 11.0]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([15.191, -8.34 ]) 8.125]\n"," [array([ 19.399, -13.905]) 13.875]\n"," [array([13.799, -6.963]) 6.75]\n"," [array([16.265, -9.181]) 8.9375]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 19.661, -16.869]) 16.5]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 990021 \t return [ 1.071 -1.173], ([1.58  0.587]), new return [12.765  1.218] \t value loss 1.981E-02 \t policy loss 1.980E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 17.73 , -12.113]) 12.0]\n"," [array([ 0.82, -1.99]) 2.0]\n"," [array([ 19.661, -14.229]) 14.25]\n"," [array([ 19.399, -13.905]) 13.875]\n"," [array([15.191, -8.34 ]) 8.125]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([13.799, -6.963]) 6.75]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 990896 \t return [11.865 -5.251], ([1.907e-06 4.768e-07]), new return [13.549 -5.084] \t value loss 1.218E-01 \t policy loss 4.090E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 19.661, -14.229]) 14.25]\n"," [array([15.191, -8.34 ]) 8.125]\n"," [array([ 3.406, -2.919]) 2.875]\n"," [array([ 19.399, -13.905]) 13.875]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 17.73 , -12.113]) 12.0]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([15.997, -9.588]) 9.4375]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 991683 \t return [ 2.543 -1.506], ([3.28  0.901]), new return [ 9.756 -2.423] \t value loss 2.319E-02 \t policy loss 5.763E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.67 , -10.153]) 10.0]\n"," [array([ 3.406, -2.919]) 2.875]\n"," [array([ 19.399, -13.905]) 13.875]\n"," [array([13.591, -7.35 ]) 7.1875]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 18.   , -10.952]) 10.75]\n"," [array([15.191, -8.34 ]) 8.125]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 992989 \t return [ 20.434 -22.835], ([1.4   0.902]), new return [ 23.465 -23.894] \t value loss 1.717E-02 \t policy loss 2.901E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.191, -8.34 ]) 8.125]\n"," [array([ 18.   , -10.952]) 10.75]\n"," [array([ 3.406, -2.919]) 2.875]\n"," [array([14.158, -8.034]) 7.8125]\n"," [array([13.591, -7.35 ]) 7.1875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 19.41 , -13.617]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 23.596, -27.591]) 29.9375]\n"," [array([ 0.7, -1. ]) 1.0]]\n","step 993966 \t return [16.415 -9.475], ([0.078 0.276]), new return [ 19.41  -11.342] \t value loss 2.503E-02 \t policy loss 2.100E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 3.406, -2.919]) 2.875]\n"," [array([14.489, -7.696]) 7.4375]\n"," [array([13.591, -7.35 ]) 7.1875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([16.791, -9.823]) 9.5625]\n"," [array([ 18.   , -10.952]) 10.75]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 19.41 , -13.617]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 994741 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [ 6.115 -2.423] \t value loss 1.976E-02 \t policy loss 1.506E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([14.94 , -8.996]) 8.9375]\n"," [array([13.591, -7.35 ]) 7.1875]\n"," [array([ 3.431, -2.689]) 2.625]\n"," [array([14.489, -7.696]) 7.4375]\n"," [array([ 18.   , -10.952]) 10.75]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 19.41 , -13.617]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 995516 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [8.335 2.57 ] \t value loss 2.208E-02 \t policy loss 6.941E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.095, -8.458]) 8.25]\n"," [array([ 3.431, -2.689]) 2.625]\n"," [array([15.633, -9.401]) 9.1875]\n"," [array([ 18.   , -10.952]) 10.75]\n"," [array([13.591, -7.35 ]) 7.1875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 19.41 , -13.617]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 996391 \t return [12.328 -5.316], ([1.907e-06 1.431e-06]), new return [18.484 -5.09 ] \t value loss 2.225E-02 \t policy loss 4.744E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 16.949, -10.463]) 10.3125]\n"," [array([13.882, -7.871]) 7.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([13.591, -7.35 ]) 7.1875]\n"," [array([15.095, -8.458]) 8.25]\n"," [array([ 18.   , -10.952]) 10.75]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 19.41 , -13.617]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 997633 \t return [ 21.928 -20.096], ([0.711 1.446]), new return [ 23.596 -19.943] \t value loss 2.033E-02 \t policy loss 7.419E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([15.095, -8.458]) 8.25]\n"," [array([ 21.9  , -19.257]) 18.875]\n"," [array([13.882, -7.871]) 7.6875]\n"," [array([13.591, -7.35 ]) 7.1875]\n"," [array([ 18.   , -10.952]) 10.75]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 19.41 , -13.617]) 13.4375]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 998747 \t return [ 19.467 -15.055], ([1.599 1.788]), new return [ 22.807 -15.305] \t value loss 5.386E-02 \t policy loss 1.080E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.908, -2.55 ]) 2.5]\n"," [array([13.882, -7.871]) 7.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([13.591, -7.35 ]) 7.1875]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([16.273, -9.554]) 9.3125]\n"," [array([ 18.   , -10.952]) 10.75]\n"," [array([ 19.41 , -13.617]) 13.4375]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 999522 \t return [ 0.7 -1. ], ([5.96e-08 0.00e+00]), new return [0.7   4.721] \t value loss 3.244E-02 \t policy loss 1.429E+00 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n","training value net\n","training policy\n","Pareto Front: [[array([ 2.908, -2.55 ]) 2.5]\n"," [array([15.094, -8.713]) 8.5]\n"," [array([13.882, -7.871]) 7.6875]\n"," [array([ 2.469, -2.423]) 2.375]\n"," [array([ 16.658, -10.437]) 10.3125]\n"," [array([ 18.   , -10.952]) 10.75]\n"," [array([ 18.484, -12.133]) 12.0]\n"," [array([12.765, -6.17 ]) 5.9375]\n"," [array([ 22.537, -19.726]) 19.25]\n"," [array([ 19.41 , -13.617]) 13.4375]\n"," [array([11.472, -5.084]) 4.875]\n"," [array([ 9.787, -3.941]) 3.875]\n"," [array([ 23.465, -25.422]) 25.6875]\n"," [array([ 21.141, -18.568]) 18.0]\n"," [array([ 4.44 , -2.972]) 2.875]\n"," [array([ 23.365, -21.131]) 21.5]\n"," [array([ 20.521, -15.305]) 15.25]\n"," [array([ 8.335, -3.014]) 3.0]\n"," [array([ 0.7, -1. ]) 1.0]\n"," [array([ 23.596, -27.591]) 29.9375]]\n","step 1000447 \t return [14.06  -7.315], ([0.000e+00 2.384e-06]), new return [13.882 -7.41 ] \t value loss 1.684E-02 \t policy loss 4.089E-01 \t popf loss 0.000E+00\n","Truncated eval episodes:  0\n"]}],"source":["env = mo_gym.make(\"deep-sea-treasure-v0\")\n","agent = MO_AWR(env, log=False, td_lambda=.95, use_popf=False, max_buffer_size=1024, value_lr=1e-4, policy_lr=5e-4, batch_size=16, cd_threshold=0.2, beta=.5, l2_critic=0, use_critic_msbe=False, use_is_weighting=False)\n","\n","agent.train(1000000, 512, num_value_steps=500, num_policy_steps=250, num_pf_points=20, num_expl_episodes=25, prio_sampling=False)"]},{"cell_type":"code","source":["!zip -r /content/results.zip /content/Results/"],"metadata":{"id":"oM5zEvS0yLdx","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1746106275430,"user_tz":-120,"elapsed":1442,"user":{"displayName":"Liam Mertens","userId":"17654526473594897979"}},"outputId":"9770a0fb-e892-4b39-974b-174af6c97c29"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/Results/ (stored 0%)\n","  adding: content/Results/training_plot_122.png (deflated 16%)\n","  adding: content/Results/training_plot_619.png (deflated 10%)\n","  adding: content/Results/training_plot_651.png (deflated 12%)\n","  adding: content/Results/training_plot_9.png (deflated 12%)\n","  adding: content/Results/training_plot_197.png (deflated 15%)\n","  adding: content/Results/training_plot_634.png (deflated 11%)\n","  adding: content/Results/training_plot_149.png (deflated 16%)\n","  adding: content/Results/training_plot_495.png (deflated 11%)\n","  adding: content/Results/training_plot_424.png (deflated 11%)\n","  adding: content/Results/training_plot_447.png (deflated 14%)\n","  adding: content/Results/training_plot_406.png (deflated 11%)\n","  adding: content/Results/training_plot_922.png (deflated 11%)\n","  adding: content/Results/training_plot_583.png (deflated 10%)\n","  adding: content/Results/training_plot_289.png (deflated 14%)\n","  adding: content/Results/training_plot_203.png (deflated 15%)\n","  adding: content/Results/training_plot_72.png (deflated 16%)\n","  adding: content/Results/training_plot_918.png (deflated 12%)\n","  adding: content/Results/training_plot_534.png (deflated 11%)\n","  adding: content/Results/training_plot_569.png (deflated 11%)\n","  adding: content/Results/training_plot_919.png (deflated 11%)\n","  adding: content/Results/training_plot_872.png (deflated 12%)\n","  adding: content/Results/training_plot_950.png (deflated 11%)\n","  adding: content/Results/training_plot_864.png (deflated 11%)\n","  adding: content/Results/training_plot_525.png (deflated 11%)\n","  adding: content/Results/training_plot_240.png (deflated 14%)\n","  adding: content/Results/training_plot_526.png (deflated 11%)\n","  adding: content/Results/training_plot_935.png (deflated 12%)\n","  adding: content/Results/training_plot_724.png (deflated 12%)\n","  adding: content/Results/training_plot_516.png (deflated 11%)\n","  adding: content/Results/training_plot_752.png (deflated 11%)\n","  adding: content/Results/training_plot_576.png (deflated 11%)\n","  adding: content/Results/training_plot_355.png (deflated 12%)\n","  adding: content/Results/training_plot_813.png (deflated 11%)\n","  adding: content/Results/training_plot_65.png (deflated 16%)\n","  adding: content/Results/training_plot_178.png (deflated 14%)\n","  adding: content/Results/training_plot_193.png (deflated 14%)\n","  adding: content/Results/training_plot_679.png (deflated 12%)\n","  adding: content/Results/training_plot_539.png (deflated 11%)\n","  adding: content/Results/training_plot_879.png (deflated 12%)\n","  adding: content/Results/training_plot_234.png (deflated 15%)\n","  adding: content/Results/training_plot_227.png (deflated 14%)\n","  adding: content/Results/training_plot_795.png (deflated 11%)\n","  adding: content/Results/training_plot_871.png (deflated 12%)\n","  adding: content/Results/training_plot_897.png (deflated 12%)\n","  adding: content/Results/training_plot_352.png (deflated 13%)\n","  adding: content/Results/training_plot_842.png (deflated 11%)\n","  adding: content/Results/training_plot_621.png (deflated 12%)\n","  adding: content/Results/training_plot_183.png (deflated 14%)\n","  adding: content/Results/training_plot_151.png (deflated 16%)\n","  adding: content/Results/training_plot_923.png (deflated 11%)\n","  adding: content/Results/training_plot_339.png (deflated 12%)\n","  adding: content/Results/training_plot_737.png (deflated 12%)\n","  adding: content/Results/training_plot_303.png (deflated 15%)\n","  adding: content/Results/training_plot_470.png (deflated 11%)\n","  adding: content/Results/training_plot_708.png (deflated 11%)\n","  adding: content/Results/training_plot_559.png (deflated 10%)\n","  adding: content/Results/training_plot_556.png (deflated 11%)\n","  adding: content/Results/training_plot_257.png (deflated 14%)\n","  adding: content/Results/training_plot_84.png (deflated 17%)\n","  adding: content/Results/training_plot_959.png (deflated 12%)\n","  adding: content/Results/training_plot_702.png (deflated 12%)\n","  adding: content/Results/training_plot_57.png (deflated 16%)\n","  adding: content/Results/training_plot_309.png (deflated 14%)\n","  adding: content/Results/training_plot_505.png (deflated 10%)\n","  adding: content/Results/training_plot_273.png (deflated 14%)\n","  adding: content/Results/training_plot_300.png (deflated 13%)\n","  adding: content/Results/training_plot_160.png (deflated 14%)\n","  adding: content/Results/training_plot_478.png (deflated 11%)\n","  adding: content/Results/training_plot_675.png (deflated 12%)\n","  adding: content/Results/training_plot_665.png (deflated 11%)\n","  adding: content/Results/training_plot_64.png (deflated 16%)\n","  adding: content/Results/training_plot_112.png (deflated 17%)\n","  adding: content/Results/training_plot_54.png (deflated 16%)\n","  adding: content/Results/training_plot_215.png (deflated 15%)\n","  adding: content/Results/training_plot_604.png (deflated 11%)\n","  adding: content/Results/training_plot_96.png (deflated 17%)\n","  adding: content/Results/training_plot_416.png (deflated 12%)\n","  adding: content/Results/training_plot_356.png (deflated 12%)\n","  adding: content/Results/training_plot_168.png (deflated 15%)\n","  adding: content/Results/training_plot_939.png (deflated 12%)\n","  adding: content/Results/training_plot_15.png (deflated 12%)\n","  adding: content/Results/training_plot_224.png (deflated 15%)\n","  adding: content/Results/training_plot_87.png (deflated 17%)\n","  adding: content/Results/training_plot_222.png (deflated 14%)\n","  adding: content/Results/training_plot_882.png (deflated 11%)\n","  adding: content/Results/training_plot_401.png (deflated 11%)\n","  adding: content/Results/training_plot_432.png (deflated 10%)\n","  adding: content/Results/training_plot_780.png (deflated 12%)\n","  adding: content/Results/training_plot_890.png (deflated 11%)\n","  adding: content/Results/training_plot_391.png (deflated 12%)\n","  adding: content/Results/training_plot_726.png (deflated 12%)\n","  adding: content/Results/training_plot_841.png (deflated 12%)\n","  adding: content/Results/training_plot_899.png (deflated 11%)\n","  adding: content/Results/training_plot_143.png (deflated 16%)\n","  adding: content/Results/training_plot_267.png (deflated 14%)\n","  adding: content/Results/training_plot_457.png (deflated 11%)\n","  adding: content/Results/training_plot_269.png (deflated 15%)\n","  adding: content/Results/training_plot_281.png (deflated 14%)\n","  adding: content/Results/training_plot_616.png (deflated 11%)\n","  adding: content/Results/training_plot_22.png (deflated 12%)\n","  adding: content/Results/training_plot_580.png (deflated 11%)\n","  adding: content/Results/training_plot_121.png (deflated 17%)\n","  adding: content/Results/training_plot_453.png (deflated 11%)\n","  adding: content/Results/training_plot_190.png (deflated 15%)\n","  adding: content/Results/training_plot_712.png (deflated 11%)\n","  adding: content/Results/training_plot_822.png (deflated 12%)\n","  adding: content/Results/training_plot_943.png (deflated 12%)\n","  adding: content/Results/training_plot_720.png (deflated 12%)\n","  adding: content/Results/training_plot_403.png (deflated 12%)\n","  adding: content/Results/training_plot_843.png (deflated 12%)\n","  adding: content/Results/training_plot_830.png (deflated 12%)\n","  adding: content/Results/training_plot_538.png (deflated 11%)\n","  adding: content/Results/training_plot_128.png (deflated 16%)\n","  adding: content/Results/training_plot_758.png (deflated 11%)\n","  adding: content/Results/training_plot_345.png (deflated 13%)\n","  adding: content/Results/training_plot_615.png (deflated 12%)\n","  adding: content/Results/training_plot_565.png (deflated 10%)\n","  adding: content/Results/training_plot_666.png (deflated 12%)\n","  adding: content/Results/training_plot_219.png (deflated 14%)\n","  adding: content/Results/training_plot_450.png (deflated 15%)\n","  adding: content/Results/training_plot_489.png (deflated 11%)\n","  adding: content/Results/training_plot_347.png (deflated 12%)\n","  adding: content/Results/training_plot_851.png (deflated 12%)\n","  adding: content/Results/training_plot_89.png (deflated 17%)\n","  adding: content/Results/training_plot_296.png (deflated 15%)\n","  adding: content/Results/training_plot_560.png (deflated 11%)\n","  adding: content/Results/training_plot_174.png (deflated 14%)\n","  adding: content/Results/training_plot_662.png (deflated 11%)\n","  adding: content/Results/training_plot_440.png (deflated 11%)\n","  adding: content/Results/training_plot_465.png (deflated 11%)\n","  adding: content/Results/training_plot_291.png (deflated 15%)\n","  adding: content/Results/training_plot_784.png (deflated 12%)\n","  adding: content/Results/training_plot_307.png (deflated 14%)\n","  adding: content/Results/training_plot_85.png (deflated 17%)\n","  adding: content/Results/training_plot_333.png (deflated 14%)\n","  adding: content/Results/training_plot_412.png (deflated 12%)\n","  adding: content/Results/training_plot_473.png (deflated 11%)\n","  adding: content/Results/training_plot_119.png (deflated 16%)\n","  adding: content/Results/training_plot_274.png (deflated 15%)\n","  adding: content/Results/training_plot_530.png (deflated 10%)\n","  adding: content/Results/training_plot_323.png (deflated 15%)\n","  adding: content/Results/training_plot_209.png (deflated 14%)\n","  adding: content/Results/training_plot_186.png (deflated 15%)\n","  adding: content/Results/training_plot_464.png (deflated 11%)\n","  adding: content/Results/training_plot_894.png (deflated 11%)\n","  adding: content/Results/training_plot_803.png (deflated 12%)\n","  adding: content/Results/training_plot_362.png (deflated 12%)\n","  adding: content/Results/training_plot_555.png (deflated 10%)\n","  adding: content/Results/training_plot_402.png (deflated 12%)\n","  adding: content/Results/training_plot_657.png (deflated 11%)\n","  adding: content/Results/training_plot_727.png (deflated 12%)\n","  adding: content/Results/training_plot_809.png (deflated 12%)\n","  adding: content/Results/training_plot_82.png (deflated 17%)\n","  adding: content/Results/training_plot_934.png (deflated 11%)\n","  adding: content/Results/training_plot_382.png (deflated 12%)\n","  adding: content/Results/training_plot_436.png (deflated 11%)\n","  adding: content/Results/training_plot_130.png (deflated 17%)\n","  adding: content/Results/training_plot_483.png (deflated 11%)\n","  adding: content/Results/training_plot_817.png (deflated 12%)\n","  adding: content/Results/training_plot_823.png (deflated 12%)\n","  adding: content/Results/training_plot_426.png (deflated 11%)\n","  adding: content/Results/training_plot_305.png (deflated 14%)\n","  adding: content/Results/training_plot_600.png (deflated 12%)\n","  adding: content/Results/training_plot_55.png (deflated 16%)\n","  adding: content/Results/training_plot_11.png (deflated 12%)\n","  adding: content/Results/training_plot_924.png (deflated 11%)\n","  adding: content/Results/training_plot_972.png (deflated 11%)\n","  adding: content/Results/training_plot_805.png (deflated 11%)\n","  adding: content/Results/training_plot_45.png (deflated 16%)\n","  adding: content/Results/training_plot_606.png (deflated 11%)\n","  adding: content/Results/training_plot_366.png (deflated 12%)\n","  adding: content/Results/training_plot_529.png (deflated 10%)\n","  adding: content/Results/training_plot_523.png (deflated 11%)\n","  adding: content/Results/training_plot_247.png (deflated 14%)\n","  adding: content/Results/training_plot_814.png (deflated 11%)\n","  adding: content/Results/training_plot_904.png (deflated 11%)\n","  adding: content/Results/training_plot_501.png (deflated 11%)\n","  adding: content/Results/training_plot_479.png (deflated 11%)\n","  adding: content/Results/training_plot_148.png (deflated 15%)\n","  adding: content/Results/training_plot_975.png (deflated 11%)\n","  adding: content/Results/training_plot_637.png (deflated 11%)\n","  adding: content/Results/training_plot_546.png (deflated 10%)\n","  adding: content/Results/training_plot_717.png (deflated 11%)\n","  adding: content/Results/training_plot_691.png (deflated 11%)\n","  adding: content/Results/training_plot_233.png (deflated 15%)\n","  adding: content/Results/training_plot_461.png (deflated 11%)\n","  adding: content/Results/training_plot_810.png (deflated 12%)\n","  adding: content/Results/training_plot_7.png (deflated 12%)\n","  adding: content/Results/training_plot_627.png (deflated 11%)\n","  adding: content/Results/training_plot_591.png (deflated 11%)\n","  adding: content/Results/training_plot_378.png (deflated 12%)\n","  adding: content/Results/training_plot_731.png (deflated 11%)\n","  adding: content/Results/training_plot_566.png (deflated 11%)\n","  adding: content/Results/training_plot_963.png (deflated 12%)\n","  adding: content/Results/training_plot_954.png (deflated 12%)\n","  adding: content/Results/training_plot_989.png (deflated 12%)\n","  adding: content/Results/training_plot_789.png (deflated 12%)\n","  adding: content/Results/training_plot_592.png (deflated 11%)\n","  adding: content/Results/training_plot_987.png (deflated 11%)\n","  adding: content/Results/training_plot_133.png (deflated 16%)\n","  adding: content/Results/training_plot_664.png (deflated 12%)\n","  adding: content/Results/training_plot_672.png (deflated 12%)\n","  adding: content/Results/training_plot_466.png (deflated 11%)\n","  adding: content/Results/training_plot_236.png (deflated 13%)\n","  adding: content/Results/training_plot_298.png (deflated 15%)\n","  adding: content/Results/training_plot_225.png (deflated 14%)\n","  adding: content/Results/training_plot_159.png (deflated 14%)\n","  adding: content/Results/training_plot_833.png (deflated 11%)\n","  adding: content/Results/training_plot_417.png (deflated 11%)\n","  adding: content/Results/training_plot_49.png (deflated 15%)\n","  adding: content/Results/training_plot_757.png (deflated 11%)\n","  adding: content/Results/training_plot_715.png (deflated 11%)\n","  adding: content/Results/training_plot_966.png (deflated 11%)\n","  adding: content/Results/training_plot_325.png (deflated 15%)\n","  adding: content/Results/training_plot_381.png (deflated 12%)\n","  adding: content/Results/training_plot_847.png (deflated 11%)\n","  adding: content/Results/training_plot_78.png (deflated 17%)\n","  adding: content/Results/training_plot_253.png (deflated 14%)\n","  adding: content/Results/training_plot_91.png (deflated 17%)\n","  adding: content/Results/training_plot_335.png (deflated 15%)\n","  adding: content/Results/training_plot_270.png (deflated 14%)\n","  adding: content/Results/training_plot_786.png (deflated 11%)\n","  adding: content/Results/training_plot_142.png (deflated 16%)\n","  adding: content/Results/training_plot_928.png (deflated 11%)\n","  adding: content/Results/training_plot_532.png (deflated 10%)\n","  adding: content/Results/training_plot_510.png (deflated 11%)\n","  adding: content/Results/training_plot_75.png (deflated 17%)\n","  adding: content/Results/training_plot_617.png (deflated 12%)\n","  adding: content/Results/training_plot_180.png (deflated 15%)\n","  adding: content/Results/training_plot_787.png (deflated 11%)\n","  adding: content/Results/training_plot_368.png (deflated 12%)\n","  adding: content/Results/training_plot_782.png (deflated 12%)\n","  adding: content/Results/training_plot_756.png (deflated 12%)\n","  adding: content/Results/training_plot_170.png (deflated 14%)\n","  adding: content/Results/training_plot_642.png (deflated 11%)\n","  adding: content/Results/training_plot_735.png (deflated 11%)\n","  adding: content/Results/training_plot_638.png (deflated 12%)\n","  adding: content/Results/training_plot_506.png (deflated 11%)\n","  adding: content/Results/training_plot_866.png (deflated 11%)\n","  adding: content/Results/training_plot_73.png (deflated 17%)\n","  adding: content/Results/training_plot_31.png (deflated 15%)\n","  adding: content/Results/training_plot_503.png (deflated 10%)\n","  adding: content/Results/training_plot_316.png (deflated 14%)\n","  adding: content/Results/training_plot_753.png (deflated 12%)\n","  adding: content/Results/training_plot_547.png (deflated 11%)\n","  adding: content/Results/training_plot_226.png (deflated 14%)\n","  adding: content/Results/training_plot_107.png (deflated 17%)\n","  adding: content/Results/training_plot_302.png (deflated 15%)\n","  adding: content/Results/training_plot_568.png (deflated 11%)\n","  adding: content/Results/training_plot_242.png (deflated 15%)\n","  adding: content/Results/training_plot_275.png (deflated 14%)\n","  adding: content/Results/training_plot_40.png (deflated 16%)\n","  adding: content/Results/training_plot_445.png (deflated 11%)\n","  adding: content/Results/training_plot_88.png (deflated 17%)\n","  adding: content/Results/training_plot_776.png (deflated 12%)\n","  adding: content/Results/training_plot_557.png (deflated 11%)\n","  adding: content/Results/training_plot_95.png (deflated 17%)\n","  adding: content/Results/training_plot_3.png (deflated 12%)\n","  adding: content/Results/training_plot_800.png (deflated 12%)\n","  adding: content/Results/training_plot_781.png (deflated 12%)\n","  adding: content/Results/training_plot_448.png (deflated 14%)\n","  adding: content/Results/training_plot_650.png (deflated 12%)\n","  adding: content/Results/training_plot_968.png (deflated 11%)\n","  adding: content/Results/training_plot_836.png (deflated 12%)\n","  adding: content/Results/training_plot_388.png (deflated 11%)\n","  adding: content/Results/training_plot_584.png (deflated 11%)\n","  adding: content/Results/training_plot_517.png (deflated 14%)\n","  adding: content/Results/training_plot_676.png (deflated 11%)\n","  adding: content/Results/training_plot_759.png (deflated 11%)\n","  adding: content/Results/training_plot_135.png (deflated 16%)\n","  adding: content/Results/training_plot_208.png (deflated 14%)\n","  adding: content/Results/training_plot_829.png (deflated 12%)\n","  adding: content/Results/training_plot_27.png (deflated 14%)\n","  adding: content/Results/training_plot_317.png (deflated 14%)\n","  adding: content/Results/training_plot_380.png (deflated 12%)\n","  adding: content/Results/training_plot_811.png (deflated 11%)\n","  adding: content/Results/training_plot_777.png (deflated 12%)\n","  adding: content/Results/training_plot_734.png (deflated 12%)\n","  adding: content/Results/training_plot_386.png (deflated 12%)\n","  adding: content/Results/training_plot_395.png (deflated 11%)\n","  adding: content/Results/training_plot_13.png (deflated 11%)\n","  adding: content/Results/training_plot_790.png (deflated 12%)\n","  adding: content/Results/training_plot_351.png (deflated 12%)\n","  adding: content/Results/training_plot_284.png (deflated 14%)\n","  adding: content/Results/training_plot_589.png (deflated 11%)\n","  adding: content/Results/training_plot_678.png (deflated 12%)\n","  adding: content/Results/training_plot_648.png (deflated 12%)\n","  adding: content/Results/training_plot_659.png (deflated 12%)\n","  adding: content/Results/training_plot_241.png (deflated 15%)\n","  adding: content/Results/training_plot_578.png (deflated 11%)\n","  adding: content/Results/training_plot_415.png (deflated 11%)\n","  adding: content/Results/training_plot_485.png (deflated 11%)\n","  adding: content/Results/training_plot_337.png (deflated 14%)\n","  adding: content/Results/training_plot_279.png (deflated 14%)\n","  adding: content/Results/training_plot_957.png (deflated 12%)\n","  adding: content/Results/training_plot_674.png (deflated 12%)\n","  adding: content/Results/training_plot_743.png (deflated 11%)\n","  adding: content/Results/training_plot_658.png (deflated 12%)\n","  adding: content/Results/training_plot_120.png (deflated 16%)\n","  adding: content/Results/training_plot_379.png (deflated 12%)\n","  adding: content/Results/training_plot_848.png (deflated 11%)\n","  adding: content/Results/training_plot_769.png (deflated 11%)\n","  adding: content/Results/training_plot_217.png (deflated 14%)\n","  adding: content/Results/training_plot_921.png (deflated 12%)\n","  adding: content/Results/training_plot_6.png (deflated 12%)\n","  adding: content/Results/training_plot_815.png (deflated 12%)\n","  adding: content/Results/training_plot_875.png (deflated 12%)\n","  adding: content/Results/training_plot_749.png (deflated 11%)\n","  adding: content/Results/training_plot_8.png (deflated 12%)\n","  adding: content/Results/training_plot_816.png (deflated 12%)\n","  adding: content/Results/training_plot_86.png (deflated 17%)\n","  adding: content/Results/training_plot_166.png (deflated 14%)\n","  adding: content/Results/training_plot_865.png (deflated 11%)\n","  adding: content/Results/training_plot_607.png (deflated 12%)\n","  adding: content/Results/training_plot_732.png (deflated 12%)\n","  adding: content/Results/training_plot_946.png (deflated 12%)\n","  adding: content/Results/training_plot_77.png (deflated 17%)\n","  adding: content/Results/training_plot_243.png (deflated 14%)\n","  adding: content/Results/training_plot_543.png (deflated 10%)\n","  adding: content/Results/training_plot_703.png (deflated 12%)\n","  adding: content/Results/training_plot_884.png (deflated 11%)\n","  adding: content/Results/training_plot_493.png (deflated 11%)\n","  adding: content/Results/training_plot_12.png (deflated 12%)\n","  adding: content/Results/training_plot_798.png (deflated 12%)\n","  adding: content/Results/training_plot_898.png (deflated 11%)\n","  adding: content/Results/training_plot_869.png (deflated 11%)\n","  adding: content/Results/training_plot_200.png (deflated 15%)\n","  adding: content/Results/training_plot_986.png (deflated 12%)\n","  adding: content/Results/training_plot_408.png (deflated 11%)\n","  adding: content/Results/training_plot_773.png (deflated 12%)\n","  adding: content/Results/training_plot_36.png (deflated 16%)\n","  adding: content/Results/training_plot_858.png (deflated 12%)\n","  adding: content/Results/training_plot_840.png (deflated 11%)\n","  adding: content/Results/training_plot_926.png (deflated 11%)\n","  adding: content/Results/training_plot_327.png (deflated 15%)\n","  adding: content/Results/training_plot_488.png (deflated 11%)\n","  adding: content/Results/training_plot_97.png (deflated 17%)\n","  adding: content/Results/training_plot_35.png (deflated 16%)\n","  adding: content/Results/training_plot_524.png (deflated 11%)\n","  adding: content/Results/training_plot_885.png (deflated 11%)\n","  adding: content/Results/training_plot_880.png (deflated 12%)\n","  adding: content/Results/training_plot_931.png (deflated 11%)\n","  adding: content/Results/training_plot_331.png (deflated 15%)\n","  adding: content/Results/training_plot_608.png (deflated 12%)\n","  adding: content/Results/training_plot_184.png (deflated 14%)\n","  adding: content/Results/training_plot_602.png (deflated 11%)\n","  adding: content/Results/training_plot_725.png (deflated 12%)\n","  adding: content/Results/training_plot_536.png (deflated 10%)\n","  adding: content/Results/training_plot_983.png (deflated 12%)\n","  adding: content/Results/training_plot_586.png (deflated 11%)\n","  adding: content/Results/training_plot_684.png (deflated 11%)\n","  adding: content/Results/training_plot_134.png (deflated 16%)\n","  adding: content/Results/training_plot_326.png (deflated 14%)\n","  adding: content/Results/training_plot_4.png (deflated 12%)\n","  adding: content/Results/training_plot_285.png (deflated 14%)\n","  adding: content/Results/training_plot_313.png (deflated 14%)\n","  adding: content/Results/training_plot_965.png (deflated 11%)\n","  adding: content/Results/training_plot_716.png (deflated 12%)\n","  adding: content/Results/training_plot_714.png (deflated 12%)\n","  adding: content/Results/training_plot_442.png (deflated 11%)\n","  adding: content/Results/training_plot_62.png (deflated 16%)\n","  adding: content/Results/training_plot_850.png (deflated 12%)\n","  adding: content/Results/training_plot_98.png (deflated 16%)\n","  adding: content/Results/training_plot_574.png (deflated 10%)\n","  adding: content/Results/training_plot_346.png (deflated 12%)\n","  adding: content/Results/training_plot_103.png (deflated 16%)\n","  adding: content/Results/training_plot_980.png (deflated 12%)\n","  adding: content/Results/training_plot_643.png (deflated 12%)\n","  adding: content/Results/training_plot_685.png (deflated 11%)\n","  adding: content/Results/training_plot_881.png (deflated 11%)\n","  adding: content/Results/training_plot_868.png (deflated 11%)\n","  adding: content/Results/training_plot_318.png (deflated 15%)\n","  adding: content/Results/training_plot_124.png (deflated 17%)\n","  adding: content/Results/training_plot_914.png (deflated 12%)\n","  adding: content/Results/training_plot_754.png (deflated 11%)\n","  adding: content/Results/training_plot_358.png (deflated 13%)\n","  adding: content/Results/training_plot_328.png (deflated 14%)\n","  adding: content/Results/training_plot_294.png (deflated 15%)\n","  adding: content/Results/training_plot_156.png (deflated 14%)\n","  adding: content/Results/training_plot_2.png (deflated 13%)\n","  adding: content/Results/training_plot_220.png (deflated 15%)\n","  adding: content/Results/training_plot_349.png (deflated 12%)\n","  adding: content/Results/training_plot_177.png (deflated 14%)\n","  adding: content/Results/training_plot_835.png (deflated 12%)\n","  adding: content/Results/training_plot_967.png (deflated 11%)\n","  adding: content/Results/training_plot_105.png (deflated 17%)\n","  adding: content/Results/training_plot_940.png (deflated 11%)\n","  adding: content/Results/training_plot_390.png (deflated 11%)\n","  adding: content/Results/training_plot_419.png (deflated 11%)\n","  adding: content/Results/training_plot_228.png (deflated 14%)\n","  adding: content/Results/training_plot_883.png (deflated 12%)\n","  adding: content/Results/training_plot_893.png (deflated 12%)\n","  adding: content/Results/training_plot_171.png (deflated 15%)\n","  adding: content/Results/training_plot_310.png (deflated 14%)\n","  adding: content/Results/training_plot_372.png (deflated 12%)\n","  adding: content/Results/training_plot_888.png (deflated 11%)\n","  adding: content/Results/training_plot_942.png (deflated 11%)\n","  adding: content/Results/training_plot_707.png (deflated 12%)\n","  adding: content/Results/training_plot_930.png (deflated 11%)\n","  adding: content/Results/training_plot_927.png (deflated 11%)\n","  adding: content/Results/training_plot_873.png (deflated 12%)\n","  adding: content/Results/training_plot_745.png (deflated 11%)\n","  adding: content/Results/training_plot_114.png (deflated 16%)\n","  adding: content/Results/training_plot_639.png (deflated 11%)\n","  adding: content/Results/training_plot_878.png (deflated 11%)\n","  adding: content/Results/training_plot_889.png (deflated 11%)\n","  adding: content/Results/training_plot_545.png (deflated 10%)\n","  adding: content/Results/training_plot_728.png (deflated 11%)\n","  adding: content/Results/training_plot_194.png (deflated 15%)\n","  adding: content/Results/training_plot_314.png (deflated 14%)\n","  adding: content/Results/training_plot_730.png (deflated 12%)\n","  adding: content/Results/training_plot_175.png (deflated 14%)\n","  adding: content/Results/training_plot_467.png (deflated 11%)\n","  adding: content/Results/training_plot_214.png (deflated 15%)\n","  adding: content/Results/training_plot_719.png (deflated 12%)\n","  adding: content/Results/training_plot_522.png (deflated 11%)\n","  adding: content/Results/training_plot_912.png (deflated 12%)\n","  adding: content/Results/training_plot_312.png (deflated 15%)\n","  adding: content/Results/training_plot_892.png (deflated 12%)\n","  adding: content/Results/training_plot_196.png (deflated 15%)\n","  adding: content/Results/training_plot_286.png (deflated 15%)\n","  adding: content/Results/training_plot_195.png (deflated 15%)\n","  adding: content/Results/training_plot_537.png (deflated 11%)\n","  adding: content/Results/training_plot_343.png (deflated 12%)\n","  adding: content/Results/training_plot_29.png (deflated 15%)\n","  adding: content/Results/training_plot_785.png (deflated 11%)\n","  adding: content/Results/training_plot_775.png (deflated 11%)\n","  adding: content/Results/training_plot_690.png (deflated 12%)\n","  adding: content/Results/training_plot_43.png (deflated 15%)\n","  adding: content/Results/training_plot_593.png (deflated 11%)\n","  adding: content/Results/training_plot_365.png (deflated 12%)\n","  adding: content/Results/training_plot_596.png (deflated 11%)\n","  adding: content/Results/training_plot_255.png (deflated 14%)\n","  adding: content/Results/training_plot_496.png (deflated 11%)\n","  adding: content/Results/training_plot_50.png (deflated 16%)\n","  adding: content/Results/training_plot_610.png (deflated 12%)\n","  adding: content/Results/training_plot_260.png (deflated 14%)\n","  adding: content/Results/training_plot_468.png (deflated 11%)\n","  adding: content/Results/training_plot_458.png (deflated 11%)\n","  adding: content/Results/training_plot_231.png (deflated 15%)\n","  adding: content/Results/training_plot_947.png (deflated 12%)\n","  adding: content/Results/training_plot_713.png (deflated 11%)\n","  adding: content/Results/training_plot_824.png (deflated 12%)\n","  adding: content/Results/training_plot_259.png (deflated 15%)\n","  adding: content/Results/training_plot_694.png (deflated 12%)\n","  adding: content/Results/training_plot_150.png (deflated 16%)\n","  adding: content/Results/training_plot_976.png (deflated 11%)\n","  adding: content/Results/training_plot_278.png (deflated 14%)\n","  adding: content/Results/training_plot_854.png (deflated 11%)\n","  adding: content/Results/training_plot_739.png (deflated 11%)\n","  adding: content/Results/training_plot_960.png (deflated 12%)\n","  adding: content/Results/training_plot_779.png (deflated 11%)\n","  adding: content/Results/training_plot_792.png (deflated 12%)\n","  adding: content/Results/training_plot_375.png (deflated 12%)\n","  adding: content/Results/training_plot_654.png (deflated 12%)\n","  adding: content/Results/training_plot_52.png (deflated 16%)\n","  adding: content/Results/training_plot_645.png (deflated 12%)\n","  adding: content/Results/training_plot_428.png (deflated 11%)\n","  adding: content/Results/training_plot_932.png (deflated 11%)\n","  adding: content/Results/training_plot_984.png (deflated 12%)\n","  adding: content/Results/training_plot_765.png (deflated 12%)\n","  adding: content/Results/training_plot_10.png (deflated 12%)\n","  adding: content/Results/training_plot_41.png (deflated 16%)\n","  adding: content/Results/training_plot_951.png (deflated 11%)\n","  adding: content/Results/training_plot_896.png (deflated 12%)\n","  adding: content/Results/training_plot_806.png (deflated 11%)\n","  adding: content/Results/training_plot_722.png (deflated 12%)\n","  adding: content/Results/training_plot_140.png (deflated 16%)\n","  adding: content/Results/training_plot_414.png (deflated 11%)\n","  adding: content/Results/training_plot_476.png (deflated 11%)\n","  adding: content/Results/training_plot_988.png (deflated 11%)\n","  adding: content/Results/training_plot_238.png (deflated 15%)\n","  adding: content/Results/training_plot_261.png (deflated 14%)\n","  adding: content/Results/training_plot_705.png (deflated 11%)\n","  adding: content/Results/training_plot_632.png (deflated 12%)\n","  adding: content/Results/training_plot_437.png (deflated 11%)\n","  adding: content/Results/training_plot_418.png (deflated 11%)\n","  adding: content/Results/training_plot_680.png (deflated 11%)\n","  adding: content/Results/training_plot_487.png (deflated 11%)\n","  adding: content/Results/training_plot_334.png (deflated 15%)\n","  adding: content/Results/training_plot_377.png (deflated 12%)\n","  adding: content/Results/training_plot_263.png (deflated 14%)\n","  adding: content/Results/training_plot_161.png (deflated 14%)\n","  adding: content/Results/training_plot_540.png (deflated 11%)\n","  adding: content/Results/training_plot_94.png (deflated 16%)\n","  adding: content/Results/training_plot_626.png (deflated 11%)\n","  adding: content/Results/training_plot_153.png (deflated 16%)\n","  adding: content/Results/training_plot_443.png (deflated 14%)\n","  adding: content/Results/training_plot_44.png (deflated 16%)\n","  adding: content/Results/training_plot_113.png (deflated 17%)\n","  adding: content/Results/training_plot_900.png (deflated 12%)\n","  adding: content/Results/training_plot_480.png (deflated 11%)\n","  adding: content/Results/training_plot_360.png (deflated 12%)\n","  adding: content/Results/training_plot_304.png (deflated 15%)\n","  adding: content/Results/training_plot_677.png (deflated 12%)\n","  adding: content/Results/training_plot_902.png (deflated 11%)\n","  adding: content/Results/training_plot_212.png (deflated 15%)\n","  adding: content/Results/training_plot_81.png (deflated 17%)\n","  adding: content/Results/training_plot_237.png (deflated 14%)\n","  adding: content/Results/training_plot_74.png (deflated 17%)\n","  adding: content/Results/training_plot_535.png (deflated 11%)\n","  adding: content/Results/training_plot_733.png (deflated 11%)\n","  adding: content/Results/training_plot_421.png (deflated 10%)\n","  adding: content/Results/training_plot_579.png (deflated 11%)\n","  adding: content/Results/training_plot_794.png (deflated 12%)\n","  adding: content/Results/training_plot_20.png (deflated 12%)\n","  adding: content/Results/training_plot_462.png (deflated 11%)\n","  adding: content/Results/training_plot_58.png (deflated 15%)\n","  adding: content/Results/training_plot_344.png (deflated 12%)\n","  adding: content/Results/training_plot_542.png (deflated 11%)\n","  adding: content/Results/training_plot_79.png (deflated 17%)\n","  adding: content/Results/training_plot_353.png (deflated 12%)\n","  adding: content/Results/training_plot_21.png (deflated 12%)\n","  adding: content/Results/training_plot_251.png (deflated 14%)\n","  adding: content/Results/training_plot_973.png (deflated 11%)\n","  adding: content/Results/training_plot_176.png (deflated 14%)\n","  adding: content/Results/training_plot_849.png (deflated 12%)\n","  adding: content/Results/training_plot_612.png (deflated 11%)\n","  adding: content/Results/training_plot_132.png (deflated 16%)\n","  adding: content/Results/training_plot_710.png (deflated 12%)\n","  adding: content/Results/training_plot_90.png (deflated 17%)\n","  adding: content/Results/training_plot_348.png (deflated 12%)\n","  adding: content/Results/training_plot_846.png (deflated 12%)\n","  adding: content/Results/training_plot_100.png (deflated 17%)\n","  adding: content/Results/training_plot_686.png (deflated 12%)\n","  adding: content/Results/training_plot_937.png (deflated 11%)\n","  adding: content/Results/training_plot_979.png (deflated 11%)\n","  adding: content/Results/training_plot_955.png (deflated 11%)\n","  adding: content/Results/training_plot_301.png (deflated 14%)\n","  adding: content/Results/training_plot_764.png (deflated 12%)\n","  adding: content/Results/training_plot_481.png (deflated 11%)\n","  adding: content/Results/training_plot_828.png (deflated 12%)\n","  adding: content/Results/training_plot_205.png (deflated 15%)\n","  adding: content/Results/training_plot_548.png (deflated 11%)\n","  adding: content/Results/training_plot_410.png (deflated 12%)\n","  adding: content/Results/training_plot_439.png (deflated 11%)\n","  adding: content/Results/training_plot_287.png (deflated 14%)\n","  adding: content/Results/training_plot_895.png (deflated 12%)\n","  adding: content/Results/training_plot_136.png (deflated 16%)\n","  adding: content/Results/training_plot_519.png (deflated 11%)\n","  adding: content/Results/training_plot_449.png (deflated 14%)\n","  adding: content/Results/training_plot_915.png (deflated 11%)\n","  adding: content/Results/training_plot_137.png (deflated 16%)\n","  adding: content/Results/training_plot_633.png (deflated 11%)\n","  adding: content/Results/training_plot_152.png (deflated 16%)\n","  adding: content/Results/training_plot_901.png (deflated 12%)\n","  adding: content/Results/training_plot_108.png (deflated 16%)\n","  adding: content/Results/training_plot_239.png (deflated 15%)\n","  adding: content/Results/training_plot_908.png (deflated 11%)\n","  adding: content/Results/training_plot_575.png (deflated 11%)\n","  adding: content/Results/training_plot_644.png (deflated 12%)\n","  adding: content/Results/training_plot_630.png (deflated 12%)\n","  adding: content/Results/training_plot_761.png (deflated 12%)\n","  adding: content/Results/training_plot_363.png (deflated 13%)\n","  adding: content/Results/training_plot_24.png (deflated 14%)\n","  adding: content/Results/training_plot_832.png (deflated 12%)\n","  adding: content/Results/training_plot_216.png (deflated 14%)\n","  adding: content/Results/training_plot_181.png (deflated 15%)\n","  adding: content/Results/training_plot_117.png (deflated 16%)\n","  adding: content/Results/training_plot_374.png (deflated 12%)\n","  adding: content/Results/training_plot_768.png (deflated 11%)\n","  adding: content/Results/training_plot_463.png (deflated 11%)\n","  adding: content/Results/training_plot_498.png (deflated 11%)\n","  adding: content/Results/training_plot_647.png (deflated 11%)\n","  adding: content/Results/training_plot_252.png (deflated 14%)\n","  adding: content/Results/training_plot_295.png (deflated 15%)\n","  adding: content/Results/training_plot_167.png (deflated 15%)\n","  adding: content/Results/training_plot_929.png (deflated 11%)\n","  adding: content/Results/training_plot_581.png (deflated 13%)\n","  adding: content/Results/training_plot_513.png (deflated 11%)\n","  adding: content/Results/training_plot_742.png (deflated 12%)\n","  adding: content/Results/training_plot_562.png (deflated 10%)\n","  adding: content/Results/training_plot_913.png (deflated 11%)\n","  adding: content/Results/training_plot_770.png (deflated 11%)\n","  adding: content/Results/training_plot_392.png (deflated 12%)\n","  adding: content/Results/training_plot_700.png (deflated 12%)\n","  adding: content/Results/training_plot_265.png (deflated 14%)\n","  adding: content/Results/training_plot_660.png (deflated 11%)\n","  adding: content/Results/training_plot_920.png (deflated 11%)\n","  adding: content/Results/training_plot_695.png (deflated 11%)\n","  adding: content/Results/training_plot_767.png (deflated 11%)\n","  adding: content/Results/training_plot_819.png (deflated 12%)\n","  adding: content/Results/training_plot_853.png (deflated 11%)\n","  adding: content/Results/training_plot_369.png (deflated 12%)\n","  adding: content/Results/training_plot_839.png (deflated 12%)\n","  adding: content/Results/training_plot_67.png (deflated 16%)\n","  adding: content/Results/training_plot_599.png (deflated 11%)\n","  adding: content/Results/training_plot_736.png (deflated 12%)\n","  adding: content/Results/training_plot_192.png (deflated 15%)\n","  adding: content/Results/training_plot_211.png (deflated 14%)\n","  adding: content/Results/training_plot_689.png (deflated 12%)\n","  adding: content/Results/training_plot_451.png (deflated 14%)\n","  adding: content/Results/training_plot_494.png (deflated 10%)\n","  adding: content/Results/training_plot_407.png (deflated 11%)\n","  adding: content/Results/training_plot_796.png (deflated 12%)\n","  adding: content/Results/training_plot_859.png (deflated 11%)\n","  adding: content/Results/training_plot_290.png (deflated 15%)\n","  adding: content/Results/training_plot_218.png (deflated 14%)\n","  adding: content/Results/training_plot_514.png (deflated 11%)\n","  adding: content/Results/training_plot_827.png (deflated 12%)\n","  adding: content/Results/training_plot_17.png (deflated 11%)\n","  adding: content/Results/training_plot_109.png (deflated 16%)\n","  adding: content/Results/training_plot_977.png (deflated 11%)\n","  adding: content/Results/training_plot_502.png (deflated 10%)\n","  adding: content/Results/training_plot_669.png (deflated 11%)\n","  adding: content/Results/training_plot_982.png (deflated 11%)\n","  adding: content/Results/training_plot_587.png (deflated 11%)\n","  adding: content/Results/training_plot_438.png (deflated 11%)\n","  adding: content/Results/training_plot_258.png (deflated 14%)\n","  adding: content/Results/training_plot_573.png (deflated 11%)\n","  adding: content/Results/training_plot_508.png (deflated 11%)\n","  adding: content/Results/training_plot_956.png (deflated 12%)\n","  adding: content/Results/training_plot_182.png (deflated 15%)\n","  adding: content/Results/training_plot_791.png (deflated 12%)\n","  adding: content/Results/training_plot_635.png (deflated 12%)\n","  adding: content/Results/training_plot_288.png (deflated 14%)\n","  adding: content/Results/training_plot_571.png (deflated 11%)\n","  adding: content/Results/training_plot_141.png (deflated 16%)\n","  adding: content/Results/training_plot_738.png (deflated 11%)\n","  adding: content/Results/training_plot_455.png (deflated 11%)\n","  adding: content/Results/training_plot_969.png (deflated 11%)\n","  adding: content/Results/training_plot_308.png (deflated 15%)\n","  adding: content/Results/training_plot_860.png (deflated 11%)\n","  adding: content/Results/training_plot_1.png (deflated 13%)\n","  adding: content/Results/training_plot_541.png (deflated 11%)\n","  adding: content/Results/training_plot_826.png (deflated 12%)\n","  adding: content/Results/training_plot_254.png (deflated 14%)\n","  adding: content/Results/training_plot_472.png (deflated 11%)\n","  adding: content/Results/training_plot_169.png (deflated 15%)\n","  adding: content/Results/training_plot_962.png (deflated 11%)\n","  adding: content/Results/training_plot_499.png (deflated 11%)\n","  adding: content/Results/training_plot_825.png (deflated 12%)\n","  adding: content/Results/training_plot_264.png (deflated 15%)\n","  adding: content/Results/training_plot_59.png (deflated 16%)\n","  adding: content/Results/training_plot_115.png (deflated 16%)\n","  adding: content/Results/training_plot_387.png (deflated 11%)\n","  adding: content/Results/training_plot_970.png (deflated 11%)\n","  adding: content/Results/training_plot_213.png (deflated 14%)\n","  adding: content/Results/training_plot_430.png (deflated 12%)\n","  adding: content/Results/training_plot_774.png (deflated 11%)\n","  adding: content/Results/training_plot_704.png (deflated 12%)\n","  adding: content/Results/training_plot_19.png (deflated 11%)\n","  adding: content/Results/training_plot_474.png (deflated 11%)\n","  adding: content/Results/training_plot_46.png (deflated 16%)\n","  adding: content/Results/training_plot_277.png (deflated 14%)\n","  adding: content/Results/training_plot_512.png (deflated 11%)\n","  adding: content/Results/training_plot_698.png (deflated 12%)\n","  adding: content/Results/training_plot_812.png (deflated 12%)\n","  adding: content/Results/training_plot_857.png (deflated 11%)\n","  adding: content/Results/training_plot_431.png (deflated 11%)\n","  adding: content/Results/training_plot_245.png (deflated 14%)\n","  adding: content/Results/training_plot_891.png (deflated 11%)\n","  adding: content/Results/training_plot_99.png (deflated 16%)\n","  adding: content/Results/training_plot_341.png (deflated 12%)\n","  adding: content/Results/training_plot_33.png (deflated 15%)\n","  adding: content/Results/training_plot_306.png (deflated 14%)\n","  adding: content/Results/training_plot_399.png (deflated 11%)\n","  adding: content/Results/training_plot_422.png (deflated 11%)\n","  adding: content/Results/training_plot_83.png (deflated 17%)\n","  adding: content/Results/training_plot_280.png (deflated 14%)\n","  adding: content/Results/training_plot_191.png (deflated 13%)\n","  adding: content/Results/training_plot_357.png (deflated 12%)\n","  adding: content/Results/training_plot_34.png (deflated 15%)\n","  adding: content/Results/training_plot_570.png (deflated 10%)\n","  adding: content/Results/training_plot_688.png (deflated 12%)\n","  adding: content/Results/training_plot_477.png (deflated 10%)\n","  adding: content/Results/training_plot_509.png (deflated 10%)\n","  adding: content/Results/training_plot_670.png (deflated 12%)\n","  adding: content/Results/training_plot_490.png (deflated 11%)\n","  adding: content/Results/training_plot_162.png (deflated 14%)\n","  adding: content/Results/training_plot_491.png (deflated 10%)\n","  adding: content/Results/training_plot_398.png (deflated 12%)\n","  adding: content/Results/training_plot_459.png (deflated 11%)\n","  adding: content/Results/training_plot_551.png (deflated 11%)\n","  adding: content/Results/training_plot_425.png (deflated 11%)\n","  adding: content/Results/training_plot_564.png (deflated 11%)\n","  adding: content/Results/training_plot_925.png (deflated 11%)\n","  adding: content/Results/training_plot_330.png (deflated 14%)\n","  adding: content/Results/training_plot_250.png (deflated 15%)\n","  adding: content/Results/training_plot_531.png (deflated 11%)\n","  adding: content/Results/training_plot_911.png (deflated 11%)\n","  adding: content/Results/training_plot_32.png (deflated 15%)\n","  adding: content/Results/training_plot_741.png (deflated 12%)\n","  adding: content/Results/training_plot_744.png (deflated 11%)\n","  adding: content/Results/training_plot_863.png (deflated 12%)\n","  adding: content/Results/training_plot_856.png (deflated 12%)\n","  adding: content/Results/training_plot_601.png (deflated 11%)\n","  adding: content/Results/training_plot_164.png (deflated 14%)\n","  adding: content/Results/training_plot_486.png (deflated 11%)\n","  adding: content/Results/training_plot_435.png (deflated 10%)\n","  adding: content/Results/training_plot_272.png (deflated 14%)\n","  adding: content/Results/training_plot_709.png (deflated 12%)\n","  adding: content/Results/training_plot_886.png (deflated 11%)\n","  adding: content/Results/training_plot_48.png (deflated 15%)\n","  adding: content/Results/training_plot_597.png (deflated 11%)\n","  adding: content/Results/training_plot_981.png (deflated 11%)\n","  adding: content/Results/training_plot_622.png (deflated 11%)\n","  adding: content/Results/training_plot_324.png (deflated 15%)\n","  adding: content/Results/training_plot_393.png (deflated 12%)\n","  adding: content/Results/training_plot_618.png (deflated 11%)\n","  adding: content/Results/training_plot_636.png (deflated 11%)\n","  adding: content/Results/training_plot_454.png (deflated 14%)\n","  adding: content/Results/training_plot_111.png (deflated 17%)\n","  adding: content/Results/training_plot_492.png (deflated 10%)\n","  adding: content/Results/training_plot_594.png (deflated 11%)\n","  adding: content/Results/training_plot_63.png (deflated 16%)\n","  adding: content/Results/training_plot_429.png (deflated 11%)\n","  adding: content/Results/training_plot_656.png (deflated 11%)\n","  adding: content/Results/training_plot_783.png (deflated 12%)\n","  adding: content/Results/training_plot_185.png (deflated 14%)\n","  adding: content/Results/training_plot_201.png (deflated 15%)\n","  adding: content/Results/training_plot_748.png (deflated 11%)\n","  adding: content/Results/training_plot_230.png (deflated 14%)\n","  adding: content/Results/training_plot_527.png (deflated 11%)\n","  adding: content/Results/training_plot_145.png (deflated 15%)\n","  adding: content/Results/training_plot_763.png (deflated 12%)\n","  adding: content/Results/training_plot_354.png (deflated 13%)\n","  adding: content/Results/training_plot_746.png (deflated 12%)\n","  adding: content/Results/training_plot_818.png (deflated 11%)\n","  adding: content/Results/training_plot_653.png (deflated 12%)\n","  adding: content/Results/training_plot_697.png (deflated 12%)\n","  adding: content/Results/training_plot_23.png (deflated 13%)\n","  adding: content/Results/training_plot_855.png (deflated 12%)\n","  adding: content/Results/training_plot_423.png (deflated 11%)\n","  adding: content/Results/training_plot_173.png (deflated 14%)\n","  adding: content/Results/training_plot_640.png (deflated 11%)\n","  adding: content/Results/training_plot_427.png (deflated 11%)\n","  adding: content/Results/training_plot_223.png (deflated 13%)\n","  adding: content/Results/training_plot_397.png (deflated 11%)\n","  adding: content/Results/training_plot_144.png (deflated 15%)\n","  adding: content/Results/training_plot_804.png (deflated 11%)\n","  adding: content/Results/training_plot_515.png (deflated 11%)\n","  adding: content/Results/training_plot_394.png (deflated 12%)\n","  adding: content/Results/training_plot_801.png (deflated 12%)\n","  adding: content/Results/training_plot_361.png (deflated 13%)\n","  adding: content/Results/training_plot_751.png (deflated 11%)\n","  adding: content/Results/training_plot_696.png (deflated 11%)\n","  adding: content/Results/training_plot_484.png (deflated 10%)\n","  adding: content/Results/training_plot_511.png (deflated 10%)\n","  adding: content/Results/training_plot_907.png (deflated 11%)\n","  adding: content/Results/training_plot_68.png (deflated 16%)\n","  adding: content/Results/training_plot_862.png (deflated 12%)\n","  adding: content/Results/training_plot_572.png (deflated 14%)\n","  adding: content/Results/training_plot_887.png (deflated 11%)\n","  adding: content/Results/training_plot_552.png (deflated 10%)\n","  adding: content/Results/training_plot_18.png (deflated 12%)\n","  adding: content/Results/training_plot_917.png (deflated 12%)\n","  adding: content/Results/training_plot_367.png (deflated 12%)\n","  adding: content/Results/training_plot_248.png (deflated 14%)\n","  adding: content/Results/training_plot_246.png (deflated 15%)\n","  adding: content/Results/training_plot_26.png (deflated 14%)\n","  adding: content/Results/training_plot_129.png (deflated 16%)\n","  adding: content/Results/training_plot_933.png (deflated 12%)\n","  adding: content/Results/training_plot_944.png (deflated 12%)\n","  adding: content/Results/training_plot_165.png (deflated 14%)\n","  adding: content/Results/training_plot_500.png (deflated 11%)\n","  adding: content/Results/training_plot_158.png (deflated 15%)\n","  adding: content/Results/training_plot_232.png (deflated 15%)\n","  adding: content/Results/training_plot_80.png (deflated 17%)\n","  adding: content/Results/training_plot_5.png (deflated 12%)\n","  adding: content/Results/training_plot_750.png (deflated 11%)\n","  adding: content/Results/training_plot_693.png (deflated 12%)\n","  adding: content/Results/training_plot_235.png (deflated 14%)\n","  adding: content/Results/training_plot_845.png (deflated 12%)\n","  adding: content/Results/training_plot_821.png (deflated 12%)\n","  adding: content/Results/training_plot_39.png (deflated 16%)\n","  adding: content/Results/training_plot_861.png (deflated 12%)\n","  adding: content/Results/training_plot_762.png (deflated 12%)\n","  adding: content/Results/training_plot_179.png (deflated 14%)\n","  adding: content/Results/training_plot_554.png (deflated 11%)\n","  adding: content/Results/training_plot_400.png (deflated 11%)\n","  adding: content/Results/training_plot_319.png (deflated 14%)\n","  adding: content/Results/training_plot_964.png (deflated 12%)\n","  adding: content/Results/training_plot_199.png (deflated 14%)\n","  adding: content/Results/training_plot_941.png (deflated 11%)\n","  adding: content/Results/training_plot_229.png (deflated 14%)\n","  adding: content/Results/training_plot_163.png (deflated 14%)\n","  adding: content/Results/training_plot_409.png (deflated 11%)\n","  adding: content/Results/training_plot_903.png (deflated 11%)\n","  adding: content/Results/training_plot_990.png (deflated 12%)\n","  adding: content/Results/training_plot_624.png (deflated 11%)\n","  adding: content/Results/training_plot_376.png (deflated 13%)\n","  adding: content/Results/training_plot_673.png (deflated 11%)\n","  adding: content/Results/training_plot_729.png (deflated 11%)\n","  adding: content/Results/training_plot_340.png (deflated 12%)\n","  adding: content/Results/training_plot_188.png (deflated 14%)\n","  adding: content/Results/training_plot_588.png (deflated 11%)\n","  adding: content/Results/training_plot_807.png (deflated 12%)\n","  adding: content/Results/training_plot_338.png (deflated 14%)\n","  adding: content/Results/training_plot_332.png (deflated 14%)\n","  adding: content/Results/training_plot_671.png (deflated 13%)\n","  adding: content/Results/training_plot_613.png (deflated 11%)\n","  adding: content/Results/training_plot_139.png (deflated 16%)\n","  adding: content/Results/training_plot_444.png (deflated 14%)\n","  adding: content/Results/training_plot_567.png (deflated 11%)\n","  adding: content/Results/training_plot_110.png (deflated 16%)\n","  adding: content/Results/training_plot_38.png (deflated 16%)\n","  adding: content/Results/training_plot_262.png (deflated 15%)\n","  adding: content/Results/training_plot_838.png (deflated 12%)\n","  adding: content/Results/training_plot_681.png (deflated 11%)\n","  adding: content/Results/training_plot_948.png (deflated 11%)\n","  adding: content/Results/training_plot_721.png (deflated 12%)\n","  adding: content/Results/training_plot_870.png (deflated 11%)\n","  adding: content/Results/training_plot_808.png (deflated 12%)\n","  adding: content/Results/training_plot_206.png (deflated 15%)\n","  adding: content/Results/training_plot_701.png (deflated 12%)\n","  adding: content/Results/training_plot_620.png (deflated 11%)\n","  adding: content/Results/training_plot_953.png (deflated 12%)\n","  adding: content/Results/training_plot_244.png (deflated 15%)\n","  adding: content/Results/training_plot_971.png (deflated 11%)\n","  adding: content/Results/training_plot_874.png (deflated 12%)\n","  adding: content/Results/training_plot_14.png (deflated 11%)\n","  adding: content/Results/training_plot_655.png (deflated 12%)\n","  adding: content/Results/training_plot_595.png (deflated 12%)\n","  adding: content/Results/training_plot_384.png (deflated 13%)\n","  adding: content/Results/training_plot_131.png (deflated 17%)\n","  adding: content/Results/training_plot_747.png (deflated 11%)\n","  adding: content/Results/training_plot_837.png (deflated 11%)\n","  adding: content/Results/training_plot_127.png (deflated 16%)\n","  adding: content/Results/training_plot_797.png (deflated 11%)\n","  adding: content/Results/training_plot_434.png (deflated 12%)\n","  adding: content/Results/training_plot_667.png (deflated 11%)\n","  adding: content/Results/training_plot_311.png (deflated 14%)\n","  adding: content/Results/training_plot_793.png (deflated 12%)\n","  adding: content/Results/training_plot_373.png (deflated 12%)\n","  adding: content/Results/training_plot_961.png (deflated 11%)\n","  adding: content/Results/training_plot_266.png (deflated 14%)\n","  adding: content/Results/training_plot_905.png (deflated 11%)\n","  adding: content/Results/training_plot_118.png (deflated 16%)\n","  adding: content/Results/training_plot_718.png (deflated 11%)\n","  adding: content/Results/training_plot_528.png (deflated 11%)\n","  adding: content/Results/training_plot_831.png (deflated 12%)\n","  adding: content/Results/training_plot_628.png (deflated 11%)\n","  adding: content/Results/training_plot_256.png (deflated 15%)\n","  adding: content/Results/training_plot_76.png (deflated 17%)\n","  adding: content/Results/training_plot_623.png (deflated 12%)\n","  adding: content/Results/training_plot_456.png (deflated 11%)\n","  adding: content/Results/training_plot_985.png (deflated 11%)\n","  adding: content/Results/training_plot_553.png (deflated 10%)\n","  adding: content/Results/training_plot_938.png (deflated 11%)\n","  adding: content/Results/training_plot_507.png (deflated 11%)\n","  adding: content/Results/training_plot_631.png (deflated 11%)\n","  adding: content/Results/training_plot_320.png (deflated 15%)\n","  adding: content/Results/training_plot_585.png (deflated 11%)\n","  adding: content/Results/training_plot_687.png (deflated 11%)\n","  adding: content/Results/training_plot_788.png (deflated 12%)\n","  adding: content/Results/training_plot_471.png (deflated 11%)\n","  adding: content/Results/training_plot_446.png (deflated 14%)\n","  adding: content/Results/training_plot_475.png (deflated 14%)\n","  adding: content/Results/training_plot_550.png (deflated 11%)\n","  adding: content/Results/training_plot_104.png (deflated 17%)\n","  adding: content/Results/training_plot_101.png (deflated 17%)\n","  adding: content/Results/training_plot_867.png (deflated 12%)\n","  adding: content/Results/training_plot_609.png (deflated 12%)\n","  adding: content/Results/training_plot_629.png (deflated 12%)\n","  adding: content/Results/training_plot_172.png (deflated 14%)\n","  adding: content/Results/training_plot_582.png (deflated 11%)\n","  adding: content/Results/training_plot_778.png (deflated 12%)\n","  adding: content/Results/training_plot_42.png (deflated 16%)\n","  adding: content/Results/training_plot_949.png (deflated 11%)\n","  adding: content/Results/training_plot_106.png (deflated 17%)\n","  adding: content/Results/training_plot_699.png (deflated 11%)\n","  adding: content/Results/training_plot_268.png (deflated 15%)\n","  adding: content/Results/training_plot_155.png (deflated 14%)\n","  adding: content/Results/training_plot_706.png (deflated 12%)\n","  adding: content/Results/training_plot_544.png (deflated 10%)\n","  adding: content/Results/training_plot_771.png (deflated 12%)\n","  adding: content/Results/training_plot_66.png (deflated 16%)\n","  adding: content/Results/training_plot_202.png (deflated 15%)\n","  adding: content/Results/training_plot_668.png (deflated 11%)\n","  adding: content/Results/training_plot_299.png (deflated 14%)\n","  adding: content/Results/training_plot_383.png (deflated 12%)\n","  adding: content/Results/training_plot_93.png (deflated 17%)\n","  adding: content/Results/training_plot_844.png (deflated 12%)\n","  adding: content/Results/training_plot_469.png (deflated 11%)\n","  adding: content/Results/training_plot_661.png (deflated 12%)\n","  adding: content/Results/training_plot_56.png (deflated 16%)\n","  adding: content/Results/training_plot_25.png (deflated 14%)\n","  adding: content/Results/training_plot_271.png (deflated 14%)\n","  adding: content/Results/training_plot_359.png (deflated 13%)\n","  adding: content/Results/training_plot_60.png (deflated 16%)\n","  adding: content/Results/training_plot_876.png (deflated 12%)\n","  adding: content/Results/training_plot_590.png (deflated 11%)\n","  adding: content/Results/training_plot_210.png (deflated 14%)\n","  adding: content/Results/training_plot_125.png (deflated 17%)\n","  adding: content/Results/training_plot_663.png (deflated 11%)\n","  adding: content/Results/training_plot_249.png (deflated 14%)\n","  adding: content/Results/training_plot_936.png (deflated 12%)\n","  adding: content/Results/training_plot_482.png (deflated 11%)\n","  adding: content/Results/training_plot_297.png (deflated 15%)\n","  adding: content/Results/training_plot_760.png (deflated 12%)\n","  adding: content/Results/training_plot_802.png (deflated 11%)\n","  adding: content/Results/training_plot_198.png (deflated 14%)\n","  adding: content/Results/training_plot_92.png (deflated 17%)\n","  adding: content/Results/training_plot_53.png (deflated 16%)\n","  adding: content/Results/training_plot_116.png (deflated 16%)\n","  adding: content/Results/training_plot_405.png (deflated 12%)\n","  adding: content/Results/training_plot_558.png (deflated 11%)\n","  adding: content/Results/training_plot_411.png (deflated 12%)\n","  adding: content/Results/training_plot_711.png (deflated 12%)\n","  adding: content/Results/training_plot_692.png (deflated 11%)\n","  adding: content/Results/training_plot_413.png (deflated 11%)\n","  adding: content/Results/training_plot_820.png (deflated 11%)\n","  adding: content/Results/training_plot_646.png (deflated 11%)\n","  adding: content/Results/training_plot_614.png (deflated 11%)\n","  adding: content/Results/training_plot_909.png (deflated 11%)\n","  adding: content/Results/training_plot_282.png (deflated 14%)\n","  adding: content/Results/training_plot_61.png (deflated 16%)\n","  adding: content/Results/training_plot_389.png (deflated 12%)\n","  adding: content/Results/training_plot_740.png (deflated 11%)\n","  adding: content/Results/training_plot_974.png (deflated 11%)\n","  adding: content/Results/training_plot_371.png (deflated 13%)\n","  adding: content/Results/training_plot_71.png (deflated 17%)\n","  adding: content/Results/training_plot_766.png (deflated 12%)\n","  adding: content/Results/training_plot_799.png (deflated 11%)\n","  adding: content/Results/training_plot_460.png (deflated 11%)\n","  adding: content/Results/training_plot_533.png (deflated 11%)\n","  adding: content/Results/training_plot_504.png (deflated 11%)\n","  adding: content/Results/training_plot_350.png (deflated 13%)\n","  adding: content/Results/training_plot_420.png (deflated 11%)\n","  adding: content/Results/training_plot_978.png (deflated 12%)\n","  adding: content/Results/training_plot_641.png (deflated 12%)\n","  adding: content/Results/training_plot_102.png (deflated 17%)\n","  adding: content/Results/training_plot_518.png (deflated 10%)\n","  adding: content/Results/training_plot_598.png (deflated 11%)\n","  adding: content/Results/training_plot_916.png (deflated 11%)\n","  adding: content/Results/training_plot_315.png (deflated 15%)\n","  adding: content/Results/training_plot_611.png (deflated 12%)\n","  adding: content/Results/training_plot_336.png (deflated 14%)\n","  adding: content/Results/training_plot_187.png (deflated 14%)\n","  adding: content/Results/training_plot_605.png (deflated 12%)\n","  adding: content/Results/training_plot_123.png (deflated 17%)\n","  adding: content/Results/training_plot_207.png (deflated 15%)\n","  adding: content/Results/training_plot_221.png (deflated 13%)\n","  adding: content/Results/training_plot_321.png (deflated 15%)\n","  adding: content/Results/training_plot_157.png (deflated 15%)\n","  adding: content/Results/training_plot_189.png (deflated 14%)\n","  adding: content/Results/training_plot_322.png (deflated 14%)\n","  adding: content/Results/training_plot_47.png (deflated 16%)\n","  adding: content/Results/training_plot_16.png (deflated 12%)\n","  adding: content/Results/training_plot_910.png (deflated 12%)\n","  adding: content/Results/training_plot_772.png (deflated 12%)\n","  adding: content/Results/training_plot_138.png (deflated 16%)\n","  adding: content/Results/training_plot_877.png (deflated 12%)\n","  adding: content/Results/training_plot_852.png (deflated 11%)\n","  adding: content/Results/training_plot_945.png (deflated 11%)\n","  adding: content/Results/training_plot_682.png (deflated 11%)\n","  adding: content/Results/training_plot_283.png (deflated 14%)\n","  adding: content/Results/training_plot_276.png (deflated 14%)\n","  adding: content/Results/training_plot_396.png (deflated 11%)\n","  adding: content/Results/training_plot_723.png (deflated 11%)\n","  adding: content/Results/training_plot_342.png (deflated 13%)\n","  adding: content/Results/training_plot_293.png (deflated 13%)\n","  adding: content/Results/training_plot_497.png (deflated 10%)\n","  adding: content/Results/training_plot_70.png (deflated 17%)\n","  adding: content/Results/training_plot_37.png (deflated 16%)\n","  adding: content/Results/training_plot_683.png (deflated 11%)\n","  adding: content/Results/training_plot_649.png (deflated 12%)\n","  adding: content/Results/training_plot_146.png (deflated 16%)\n","  adding: content/Results/training_plot_329.png (deflated 15%)\n","  adding: content/Results/training_plot_652.png (deflated 12%)\n","  adding: content/Results/training_plot_521.png (deflated 11%)\n","  adding: content/Results/training_plot_952.png (deflated 11%)\n","  adding: content/Results/training_plot_577.png (deflated 11%)\n","  adding: content/Results/training_plot_441.png (deflated 13%)\n","  adding: content/Results/training_plot_958.png (deflated 11%)\n","  adding: content/Results/training_plot_30.png (deflated 15%)\n","  adding: content/Results/training_plot_292.png (deflated 14%)\n","  adding: content/Results/training_plot_834.png (deflated 12%)\n","  adding: content/Results/training_plot_625.png (deflated 11%)\n","  adding: content/Results/training_plot_404.png (deflated 11%)\n","  adding: content/Results/training_plot_520.png (deflated 11%)\n","  adding: content/Results/training_plot_549.png (deflated 10%)\n","  adding: content/Results/training_plot_370.png (deflated 13%)\n","  adding: content/Results/training_plot_69.png (deflated 16%)\n","  adding: content/Results/training_plot_385.png (deflated 11%)\n","  adding: content/Results/training_plot_28.png (deflated 15%)\n","  adding: content/Results/training_plot_561.png (deflated 11%)\n","  adding: content/Results/training_plot_906.png (deflated 11%)\n","  adding: content/Results/training_plot_433.png (deflated 10%)\n","  adding: content/Results/training_plot_204.png (deflated 14%)\n","  adding: content/Results/training_plot_126.png (deflated 16%)\n","  adding: content/Results/training_plot_154.png (deflated 15%)\n","  adding: content/Results/training_plot_452.png (deflated 11%)\n","  adding: content/Results/training_plot_147.png (deflated 16%)\n","  adding: content/Results/training_plot_364.png (deflated 12%)\n","  adding: content/Results/training_plot_755.png (deflated 12%)\n","  adding: content/Results/training_plot_51.png (deflated 16%)\n","  adding: content/Results/training_plot_563.png (deflated 10%)\n","  adding: content/Results/training_plot_603.png (deflated 12%)\n"]}]},{"cell_type":"code","source":["!rm -rf /content/Results"],"metadata":{"id":"VqQrwUz-rcS5","executionInfo":{"status":"ok","timestamp":1746009379155,"user_tz":-120,"elapsed":117,"user":{"displayName":"Liam Mertens","userId":"17654526473594897979"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import torch as th\n","agent.experience_replay"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"5STgWNBbuZrj","executionInfo":{"status":"ok","timestamp":1746006369960,"user_tz":-120,"elapsed":786,"user":{"displayName":"Liam Mertens","userId":"17654526473594897979"}},"outputId":"f9e19925-2c60-4e30-ba01-488f2853bdc6"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(-2e-05,\n","  204005,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204006,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204007,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204014,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204011,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204008,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204009,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204020,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204804,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204025,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204018,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204017,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204016,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204010,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204012,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204023,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204797,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  205564,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  205562,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  204801,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204785,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204784,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204019,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204029,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204028,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204024,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  205579,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  204791,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204013,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204027,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204015,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  206343,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  204798,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  205561,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  204810,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  205568,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  209454,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  207127,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  205565,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  204808,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204805,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204800,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  205571,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  205569,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  206356,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  206367,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  204026,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.15 , -19.275], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9217636, terminal=True)]),\n"," (-2e-05,\n","  204786,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  205572,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  204806,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  206344,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  207136,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  206345,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  205582,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  206336,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  204793,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204796,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204799,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204789,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204790,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  204792,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  206368,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  205583,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  207125,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  207123,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  208678,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  211787,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  211797,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  206361,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  205581,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  209459,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  205570,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  207911,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  210238,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  210246,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  209451,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  209458,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  207898,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  207910,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  205576,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  206360,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  206338,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  206369,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  205567,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  205575,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  211792,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  205578,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  208676,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  209453,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  208697,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  208674,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  207902,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  207900,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  206337,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  206366,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  207904,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  206352,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  207914,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  208681,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  205574,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  208690,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  209460,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  207912,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  207897,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  211016,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  212582,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  212565,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  211017,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  212575,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  212569,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  208683,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  204809,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  207916,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  207921,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  208680,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  208696,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  207120,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  209449,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  207137,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  204807,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([16.362, -8.818], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8604144, terminal=True)]),\n"," (-2e-05,\n","  205563,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  205584,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  205577,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  207138,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  207130,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  211798,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  212571,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  215679,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  226550,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  208695,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  209456,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  208685,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  220339,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  219551,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  213357,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  216444,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  214119,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  214893,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  208675,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  219574,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  205585,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  210250,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  210248,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  210249,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  207128,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  209457,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  211795,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  216465,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  214896,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  214898,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  219556,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  211790,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  216443,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  218775,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  210237,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  207905,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  207903,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  209462,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  210247,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  207143,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  209450,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  221131,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  207122,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  208693,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  206339,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  207140,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  207131,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  207901,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  207121,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  214908,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  207907,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  212563,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  212579,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  207129,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  211006,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  209465,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  211019,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  210244,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  215664,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  210241,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  212561,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  213336,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  209471,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  211005,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  211785,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  213354,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  210226,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  211008,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  207906,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  228114,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  207126,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  210245,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  210225,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  208688,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  218780,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  208686,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  211028,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  216450,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  208692,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  206357,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  207146,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  217237,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  218021,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  210242,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  224225,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  209455,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  211009,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  213339,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  207899,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  214904,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  215670,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  214890,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  213337,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  213353,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  214885,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  215672,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  211027,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  221116,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  213335,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  217228,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  218795,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  210230,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  210236,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  211782,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  205566,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  212574,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  212564,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  214115,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  211804,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  208684,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  218782,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  209452,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  212568,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  208694,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  210240,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  212572,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  215662,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  212570,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  208689,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  205580,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  208679,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  207124,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  206342,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  211030,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  207139,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  207918,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  214123,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  209468,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  207908,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  217232,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  207135,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  215685,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  213333,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  215668,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  231221,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  216437,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  216439,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  226567,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  232759,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  211788,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  209470,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  211789,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  225795,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  224998,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  218008,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  222675,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  220341,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  221910,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  221125,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  214122,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  220354,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  217225,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  222667,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  221121,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  216455,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  214894,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  217998,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  215682,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  211796,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  225015,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  225791,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  207913,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  211794,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  223463,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  224232,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  214887,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  221126,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  215683,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  214891,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  207141,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  216438,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  220342,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  210229,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  220331,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  217244,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  224233,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  223460,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  224224,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  223461,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  233559,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  222688,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  227349,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  219560,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  214892,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  215665,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  220349,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  227345,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  220332,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  219568,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  222689,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  217227,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  228102,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  214110,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  213344,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  208691,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  214902,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  227330,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  214131,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  217221,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  209469,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  216454,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  212573,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  209463,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  222668,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  221905,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  211013,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  216447,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  215674,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  211802,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  224235,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  211012,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  211007,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  222686,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  228109,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  207909,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  217235,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  212578,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  207915,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  208687,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  228110,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  216464,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  220353,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  207922,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  233556,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  215673,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  220346,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  213334,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  209472,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  211004,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  211014,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  215684,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  211029,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  211786,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  228115,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  211793,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  214133,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  213345,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  221119,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  221113,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  221912,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  215681,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  214121,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  214907,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  213356,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  224242,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  217226,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  224243,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  221134,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  222672,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  214132,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  213343,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  216453,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  215666,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  212560,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  210243,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  225010,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  228112,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  211011,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  233546,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  228880,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  228898,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  207917,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -28.829], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.98074937, terminal=True)]),\n"," (-2e-05,\n","  208677,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  211791,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  214134,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  214901,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  220337,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  214905,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  211015,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  219550,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  218798,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  209461,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  218017,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  214126,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  217236,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  223456,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  221902,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  211800,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  217231,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  211003,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  223450,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  208682,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  226565,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  218018,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  217240,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  218791,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  222683,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  214116,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  211781,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  225793,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  231225,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  214127,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  214117,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  228107,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  225784,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  217238,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  220338,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  211803,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  214899,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  218790,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  225772,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  221124,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  218785,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  218774,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  225773,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  225781,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  214886,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  225779,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  217230,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  218012,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  228103,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  219575,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  219577,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  218013,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  229665,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  223455,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  225789,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  225004,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  223465,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  218794,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  218010,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  229677,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  221136,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  221901,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  225783,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  221900,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  212556,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  214111,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  212567,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  221898,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  205573,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -19.533], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8924333, terminal=True)]),\n"," (-2e-05,\n","  213352,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  220333,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  213340,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  221890,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  217241,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  223449,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  213358,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  222684,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  211801,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  212566,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  226554,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  223458,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  211018,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  209473,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  232768,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  214895,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  217239,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  213350,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  213348,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  219570,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  217222,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  229682,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  222665,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  221904,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  212577,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  217245,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  212562,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  218778,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  206353,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.57 , -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.7431431, terminal=True)]),\n"," (-2e-05,\n","  211024,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  216440,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  210239,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  215663,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  213349,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  218003,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  207142,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  214124,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  231226,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  211799,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  211784,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  225796,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  212559,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  219578,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  214128,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  215677,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  221903,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  215671,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  210232,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  217234,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  232003,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  209448,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  215667,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  231986,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  216460,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  214906,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  231216,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  215669,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  218007,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  232001,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  231222,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  217220,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  228900,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  225006,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  233537,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  228125,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  233548,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  232785,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  233558,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  228881,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  212576,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([10.786, -6.584], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90611494, terminal=True)]),\n"," (-2e-05,\n","  221133,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  235886,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  223453,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  223446,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-0.0,\n","  180687,\n","  [Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.355, -3.113], dtype=float32), value_vec=array([11.561, -4.964], dtype=float32), horizon=3, next_observation=array([0, 1], dtype=int32), action_prob=0.0066439593, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.302, -2.074], dtype=float32), value_vec=array([11.561, -3.964], dtype=float32), horizon=2, next_observation=array([1, 1], dtype=int32), action_prob=0.10695243, terminal=False),\n","   Transition(observation=array([1, 1], dtype=int32), action=1, reward=array([ 8.2, -1. ], dtype=float32), return_=array([ 8.2, -1. ], dtype=float32), value_vec=array([11.561, -2.964], dtype=float32), horizon=1, next_observation=array([2, 1], dtype=int32), action_prob=0.8998299, terminal=True)]),\n"," (-2e-05,\n","  233543,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  235874,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-0.0,\n","  186132,\n","  [Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([11.62, -7.29], dtype=float32), value_vec=array([10.625, -5.314], dtype=float32), horizon=7, next_observation=array([0, 1], dtype=int32), action_prob=0.021621032, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([11.604, -6.268], dtype=float32), value_vec=array([10.625, -4.314], dtype=float32), horizon=6, next_observation=array([0, 2], dtype=int32), action_prob=0.06370458, terminal=False),\n","   Transition(observation=array([0, 2], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([11.545, -5.175], dtype=float32), value_vec=array([10.625, -3.314], dtype=float32), horizon=5, next_observation=array([0, 2], dtype=int32), action_prob=0.5406578, terminal=False),\n","   Transition(observation=array([0, 2], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([11.511, -4.125], dtype=float32), value_vec=array([10.625, -2.314], dtype=float32), horizon=4, next_observation=array([0, 2], dtype=int32), action_prob=0.28867105, terminal=False),\n","   Transition(observation=array([0, 2], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([11.488, -3.078], dtype=float32), value_vec=array([10.625, -1.314], dtype=float32), horizon=3, next_observation=array([1, 2], dtype=int32), action_prob=0.78418386, terminal=False),\n","   Transition(observation=array([1, 2], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([11.485, -2.036], dtype=float32), value_vec=array([10.625, -0.314], dtype=float32), horizon=2, next_observation=array([2, 2], dtype=int32), action_prob=0.90220773, terminal=False),\n","   Transition(observation=array([2, 2], dtype=int32), action=1, reward=array([11.5, -1. ], dtype=float32), return_=array([11.5, -1. ], dtype=float32), value_vec=array([10.625,  0.686], dtype=float32), horizon=1, next_observation=array([3, 2], dtype=int32), action_prob=0.9492922, terminal=True)]),\n"," (-2e-05,\n","  236667,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  230439,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (1,\n","  237421,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 13.208, -13.384], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90985554, terminal=True)]),\n"," (-2e-05,\n","  224239,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  222687,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  233536,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  225018,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-0.0,\n","  135573,\n","  [Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 1.204, -2.083], dtype=float32), value_vec=array([2.525, 9.53 ], dtype=float32), horizon=2, next_observation=array([0, 0], dtype=int32), action_prob=0.17156047, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 2.525, 10.53 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.78197265, terminal=True)]),\n"," (-2e-05,\n","  224997,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  234330,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  221909,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  228905,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  225011,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  223457,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  222666,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  226574,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  235884,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  224236,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  222674,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-0.0,\n","  137134,\n","  [Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 1.252, -2.141], dtype=float32), value_vec=array([3.246, 9.683], dtype=float32), horizon=2, next_observation=array([0, 0], dtype=int32), action_prob=0.1710471, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 3.246, 10.683], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.77627194, terminal=True)]),\n"," (-2e-05,\n","  225020,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  227348,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  225788,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  235883,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  218020,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  228901,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  218019,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  225019,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  235094,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-0.0,\n","  2551,\n","  [Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -50. ], dtype=float32), value_vec=array([0., 0.]), horizon=50, next_observation=array([0, 0], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -49. ], dtype=float32), value_vec=array([0., 0.]), horizon=49, next_observation=array([0, 0], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -48. ], dtype=float32), value_vec=array([0., 0.]), horizon=48, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -47. ], dtype=float32), value_vec=array([0., 0.]), horizon=47, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -46. ], dtype=float32), value_vec=array([0., 0.]), horizon=46, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -45. ], dtype=float32), value_vec=array([0., 0.]), horizon=45, next_observation=array([1, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 1], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -44. ], dtype=float32), value_vec=array([0., 0.]), horizon=44, next_observation=array([1, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 2], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -43. ], dtype=float32), value_vec=array([0., 0.]), horizon=43, next_observation=array([1, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 3], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -42. ], dtype=float32), value_vec=array([0., 0.]), horizon=42, next_observation=array([1, 4], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 4], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -41. ], dtype=float32), value_vec=array([0., 0.]), horizon=41, next_observation=array([2, 4], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 4], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -40. ], dtype=float32), value_vec=array([0., 0.]), horizon=40, next_observation=array([3, 4], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 4], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -39. ], dtype=float32), value_vec=array([0., 0.]), horizon=39, next_observation=array([3, 5], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 5], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -38. ], dtype=float32), value_vec=array([0., 0.]), horizon=38, next_observation=array([3, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 6], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -37. ], dtype=float32), value_vec=array([0., 0.]), horizon=37, next_observation=array([2, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 6], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -36. ], dtype=float32), value_vec=array([0., 0.]), horizon=36, next_observation=array([2, 5], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 5], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -35. ], dtype=float32), value_vec=array([0., 0.]), horizon=35, next_observation=array([3, 5], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 5], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -34. ], dtype=float32), value_vec=array([0., 0.]), horizon=34, next_observation=array([2, 5], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 5], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -33. ], dtype=float32), value_vec=array([0., 0.]), horizon=33, next_observation=array([2, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 6], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -32. ], dtype=float32), value_vec=array([0., 0.]), horizon=32, next_observation=array([2, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 7], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -31. ], dtype=float32), value_vec=array([0., 0.]), horizon=31, next_observation=array([2, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 8], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -30. ], dtype=float32), value_vec=array([0., 0.]), horizon=30, next_observation=array([2, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 9], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -29. ], dtype=float32), value_vec=array([0., 0.]), horizon=29, next_observation=array([3, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 9], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -28. ], dtype=float32), value_vec=array([0., 0.]), horizon=28, next_observation=array([2, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 9], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -27. ], dtype=float32), value_vec=array([0., 0.]), horizon=27, next_observation=array([2, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 8], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -26. ], dtype=float32), value_vec=array([0., 0.]), horizon=26, next_observation=array([2, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 7], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -25. ], dtype=float32), value_vec=array([0., 0.]), horizon=25, next_observation=array([1, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 7], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -24. ], dtype=float32), value_vec=array([0., 0.]), horizon=24, next_observation=array([2, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 7], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -23. ], dtype=float32), value_vec=array([0., 0.]), horizon=23, next_observation=array([3, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 7], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -22. ], dtype=float32), value_vec=array([0., 0.]), horizon=22, next_observation=array([3, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -21. ], dtype=float32), value_vec=array([0., 0.]), horizon=21, next_observation=array([4, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([4, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -20. ], dtype=float32), value_vec=array([0., 0.]), horizon=20, next_observation=array([5, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([5, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -19. ], dtype=float32), value_vec=array([0., 0.]), horizon=19, next_observation=array([6, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([6, 8], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -18. ], dtype=float32), value_vec=array([0., 0.]), horizon=18, next_observation=array([6, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([6, 9], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -17. ], dtype=float32), value_vec=array([0., 0.]), horizon=17, next_observation=array([7, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([7, 9], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -16. ], dtype=float32), value_vec=array([0., 0.]), horizon=16, next_observation=array([ 7, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 7, 10], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -15. ], dtype=float32), value_vec=array([0., 0.]), horizon=15, next_observation=array([ 8, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 8, 10], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -14. ], dtype=float32), value_vec=array([0., 0.]), horizon=14, next_observation=array([ 7, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 7, 10], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -13. ], dtype=float32), value_vec=array([0., 0.]), horizon=13, next_observation=array([ 8, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 8, 10], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -12. ], dtype=float32), value_vec=array([0., 0.]), horizon=12, next_observation=array([ 9, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 9, 10], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -11. ], dtype=float32), value_vec=array([0., 0.]), horizon=11, next_observation=array([ 9, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 9, 10], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 23.7, -10. ], dtype=float32), value_vec=array([0., 0.]), horizon=10, next_observation=array([10, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([10, 10], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([23.7, -9. ], dtype=float32), value_vec=array([0., 0.]), horizon=9, next_observation=array([ 9, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 9, 10], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([23.7, -8. ], dtype=float32), value_vec=array([0., 0.]), horizon=8, next_observation=array([10, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([10, 10], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([23.7, -7. ], dtype=float32), value_vec=array([0., 0.]), horizon=7, next_observation=array([ 9, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 9, 10], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([23.7, -6. ], dtype=float32), value_vec=array([0., 0.]), horizon=6, next_observation=array([10, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([10, 10], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([23.7, -5. ], dtype=float32), value_vec=array([0., 0.]), horizon=5, next_observation=array([ 9, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 9, 10], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([23.7, -4. ], dtype=float32), value_vec=array([0., 0.]), horizon=4, next_observation=array([10, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([10, 10], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([23.7, -3. ], dtype=float32), value_vec=array([0., 0.]), horizon=3, next_observation=array([10, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([10, 10], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([23.7, -2. ], dtype=float32), value_vec=array([0., 0.]), horizon=2, next_observation=array([10, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([10, 10], dtype=int32), action=2, reward=array([23.7, -1. ], dtype=float32), return_=array([23.7, -1. ], dtype=float32), value_vec=array([0., 0.]), horizon=1, next_observation=array([10,  9], dtype=int32), action_prob=0.25, terminal=True)]),\n"," (-2e-05,\n","  232780,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  225017,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  234327,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  225792,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  214130,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  220352,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  227332,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  215680,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  224238,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  226566,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  229681,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  225785,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  218002,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  221112,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  236668,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  226556,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  233547,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  216448,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  221132,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  218011,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  233549,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  220357,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  226570,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  228117,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  227350,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  221913,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-0.0,\n","  135589,\n","  [Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.523, -3.278], dtype=float32), value_vec=array([2.525, 9.53 ], dtype=float32), horizon=3, next_observation=array([0, 1], dtype=int32), action_prob=0.030662334, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.359, -2.106], dtype=float32), value_vec=array([ 2.525, 10.53 ], dtype=float32), horizon=2, next_observation=array([1, 1], dtype=int32), action_prob=0.78315747, terminal=False),\n","   Transition(observation=array([1, 1], dtype=int32), action=1, reward=array([ 8.2, -1. ], dtype=float32), return_=array([ 8.2, -1. ], dtype=float32), value_vec=array([ 2.525, 11.53 ], dtype=float32), horizon=1, next_observation=array([2, 1], dtype=int32), action_prob=0.825849, terminal=True)]),\n"," (-2e-05,\n","  226573,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  235107,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  226571,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  221127,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  217997,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  227351,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (1,\n","  237424,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 13.208, -13.384], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90985554, terminal=True)]),\n"," (-2e-05,\n","  235875,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-0.0,\n","  2711,\n","  [Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([11.5, -5. ], dtype=float32), value_vec=array([0., 0.]), horizon=5, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([11.5, -4. ], dtype=float32), value_vec=array([0., 0.]), horizon=4, next_observation=array([0, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 2], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([11.5, -3. ], dtype=float32), value_vec=array([0., 0.]), horizon=3, next_observation=array([1, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 2], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([11.5, -2. ], dtype=float32), value_vec=array([0., 0.]), horizon=2, next_observation=array([2, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 2], dtype=int32), action=1, reward=array([11.5, -1. ], dtype=float32), return_=array([11.5, -1. ], dtype=float32), value_vec=array([0., 0.]), horizon=1, next_observation=array([3, 2], dtype=int32), action_prob=0.25, terminal=True)]),\n"," (-2e-05,\n","  227326,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  236653,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  226572,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-0.0,\n","  119980,\n","  [Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.746, -4.772], dtype=float32), value_vec=array([3.641, 8.416], dtype=float32), horizon=4, next_observation=array([0, 0], dtype=int32), action_prob=0.17652084, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.591, -3.402], dtype=float32), value_vec=array([3.641, 9.416], dtype=float32), horizon=3, next_observation=array([0, 1], dtype=int32), action_prob=0.030847557, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.406, -2.151], dtype=float32), value_vec=array([ 3.641, 10.416], dtype=float32), horizon=2, next_observation=array([1, 1], dtype=int32), action_prob=0.6822136, terminal=False),\n","   Transition(observation=array([1, 1], dtype=int32), action=1, reward=array([ 8.2, -1. ], dtype=float32), return_=array([ 8.2, -1. ], dtype=float32), value_vec=array([ 3.641, 11.416], dtype=float32), horizon=1, next_observation=array([2, 1], dtype=int32), action_prob=0.84856874, terminal=True)]),\n"," (-2e-05,\n","  235100,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  235103,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  227347,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  223464,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  228116,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  232766,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  231229,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  228113,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  227346,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  215686,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  222671,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  227338,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  235863,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  221120,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  236651,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-0.0,\n","  203253,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.579, -18.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9147627, terminal=True)]),\n"," (-2e-05,\n","  227343,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  220351,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  227339,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  227344,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  235878,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  229661,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  234333,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  219576,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  234311,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  231231,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  214897,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  219552,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  231984,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  227342,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  235887,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  211010,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([13.879, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89738256, terminal=True)]),\n"," (-2e-05,\n","  227327,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  227335,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  227340,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  232767,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  229660,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  227329,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  227331,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  235104,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  236654,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  221907,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  225002,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  235092,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  224245,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  218797,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  228104,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  234329,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  234326,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  228879,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  225005,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  230454,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  214120,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  217999,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  221135,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-0.0,\n","  2989,\n","  [Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 16.1, -12. ], dtype=float32), value_vec=array([0., 0.]), horizon=12, next_observation=array([0, 0], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 16.1, -11. ], dtype=float32), value_vec=array([0., 0.]), horizon=11, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 16.1, -10. ], dtype=float32), value_vec=array([0., 0.]), horizon=10, next_observation=array([1, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 1], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([16.1, -9. ], dtype=float32), value_vec=array([0., 0.]), horizon=9, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([16.1, -8. ], dtype=float32), value_vec=array([0., 0.]), horizon=8, next_observation=array([0, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 2], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([16.1, -7. ], dtype=float32), value_vec=array([0., 0.]), horizon=7, next_observation=array([0, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 3], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([16.1, -6. ], dtype=float32), value_vec=array([0., 0.]), horizon=6, next_observation=array([1, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 3], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([16.1, -5. ], dtype=float32), value_vec=array([0., 0.]), horizon=5, next_observation=array([2, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 3], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([16.1, -4. ], dtype=float32), value_vec=array([0., 0.]), horizon=4, next_observation=array([3, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 3], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([16.1, -3. ], dtype=float32), value_vec=array([0., 0.]), horizon=3, next_observation=array([3, 4], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 4], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([16.1, -2. ], dtype=float32), value_vec=array([0., 0.]), horizon=2, next_observation=array([3, 5], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 5], dtype=int32), action=1, reward=array([16.1, -1. ], dtype=float32), return_=array([16.1, -1. ], dtype=float32), value_vec=array([0., 0.]), horizon=1, next_observation=array([4, 5], dtype=int32), action_prob=0.25, terminal=True)]),\n"," (-2e-05,\n","  228896,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  224237,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  224234,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  228106,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  233538,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  233550,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  218796,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  214112,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  228108,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  227328,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  228897,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  228899,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  228111,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  235102,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  221130,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  223454,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  228890,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  236648,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  214889,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  219569,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  225021,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  228904,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  214888,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  225014,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  229673,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  235091,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  223444,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  235882,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  223442,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  235866,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  228893,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  220350,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  234315,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-0.0,\n","  1431,\n","  [Transition(observation=array([0, 0], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -30. ], dtype=float32), value_vec=array([0., 0.]), horizon=30, next_observation=array([0, 0], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -29. ], dtype=float32), value_vec=array([0., 0.]), horizon=29, next_observation=array([0, 0], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -28. ], dtype=float32), value_vec=array([0., 0.]), horizon=28, next_observation=array([0, 0], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -27. ], dtype=float32), value_vec=array([0., 0.]), horizon=27, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -26. ], dtype=float32), value_vec=array([0., 0.]), horizon=26, next_observation=array([1, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 1], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -25. ], dtype=float32), value_vec=array([0., 0.]), horizon=25, next_observation=array([1, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 2], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -24. ], dtype=float32), value_vec=array([0., 0.]), horizon=24, next_observation=array([1, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 3], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -23. ], dtype=float32), value_vec=array([0., 0.]), horizon=23, next_observation=array([1, 4], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 4], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -22. ], dtype=float32), value_vec=array([0., 0.]), horizon=22, next_observation=array([2, 4], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 4], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -21. ], dtype=float32), value_vec=array([0., 0.]), horizon=21, next_observation=array([2, 5], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 5], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -20. ], dtype=float32), value_vec=array([0., 0.]), horizon=20, next_observation=array([2, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 6], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -19. ], dtype=float32), value_vec=array([0., 0.]), horizon=19, next_observation=array([1, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 6], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -18. ], dtype=float32), value_vec=array([0., 0.]), horizon=18, next_observation=array([1, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 7], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -17. ], dtype=float32), value_vec=array([0., 0.]), horizon=17, next_observation=array([0, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 7], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -16. ], dtype=float32), value_vec=array([0., 0.]), horizon=16, next_observation=array([0, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 6], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -15. ], dtype=float32), value_vec=array([0., 0.]), horizon=15, next_observation=array([0, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 6], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -14. ], dtype=float32), value_vec=array([0., 0.]), horizon=14, next_observation=array([0, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 7], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -13. ], dtype=float32), value_vec=array([0., 0.]), horizon=13, next_observation=array([1, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 7], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -12. ], dtype=float32), value_vec=array([0., 0.]), horizon=12, next_observation=array([2, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 7], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -11. ], dtype=float32), value_vec=array([0., 0.]), horizon=11, next_observation=array([3, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 7], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 20.3, -10. ], dtype=float32), value_vec=array([0., 0.]), horizon=10, next_observation=array([4, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([4, 7], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([20.3, -9. ], dtype=float32), value_vec=array([0., 0.]), horizon=9, next_observation=array([4, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([4, 6], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([20.3, -8. ], dtype=float32), value_vec=array([0., 0.]), horizon=8, next_observation=array([5, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([5, 6], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([20.3, -7. ], dtype=float32), value_vec=array([0., 0.]), horizon=7, next_observation=array([5, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([5, 7], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([20.3, -6. ], dtype=float32), value_vec=array([0., 0.]), horizon=6, next_observation=array([5, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([5, 8], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([20.3, -5. ], dtype=float32), value_vec=array([0., 0.]), horizon=5, next_observation=array([4, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([4, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([20.3, -4. ], dtype=float32), value_vec=array([0., 0.]), horizon=4, next_observation=array([5, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([5, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([20.3, -3. ], dtype=float32), value_vec=array([0., 0.]), horizon=3, next_observation=array([6, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([6, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([20.3, -2. ], dtype=float32), value_vec=array([0., 0.]), horizon=2, next_observation=array([7, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([7, 8], dtype=int32), action=2, reward=array([20.3, -1. ], dtype=float32), return_=array([20.3, -1. ], dtype=float32), value_vec=array([0., 0.]), horizon=1, next_observation=array([7, 7], dtype=int32), action_prob=0.25, terminal=True)]),\n"," (-2e-05,\n","  215676,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  225013,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  225001,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  234328,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  219571,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  223445,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  228105,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  228895,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  214113,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  225009,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  223443,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  223447,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  225012,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  218799,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  223440,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  213351,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  224241,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  211805,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  236656,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  228118,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  222673,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  236643,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  216449,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  233554,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  224216,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  221906,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  228119,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  229680,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  221908,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  224246,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  235106,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  233539,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  225003,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  230445,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  225007,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  216456,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  221911,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  224240,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  222669,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  235109,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-0.0,\n","  210235,\n","  [Transition(observation=array([0, 0], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 1.391, -2.974], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=3, next_observation=array([0, 0], dtype=int32), action_prob=0.017306278, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 1.04 , -1.985], dtype=float32), value_vec=array([ 23.879, -25.125], dtype=float32), horizon=2, next_observation=array([0, 0], dtype=int32), action_prob=0.017709648, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -24.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97078997, terminal=True)]),\n"," (-2e-05,\n","  232771,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  228888,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  224244,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (1,\n","  237423,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 13.208, -13.384], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90985554, terminal=True)]),\n"," (-2e-05,\n","  225786,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  228889,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  229659,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  223448,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  228882,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  222679,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  228127,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  213355,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  231993,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  222685,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  231209,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  235890,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  221129,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  228878,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  214129,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  235885,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  228122,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  228126,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  232765,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (1,\n","  237422,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 13.208, -13.384], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90985554, terminal=True)]),\n"," (-2e-05,\n","  228124,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  229658,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  213338,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  235110,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  233553,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  228894,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-0.0,\n","  232776,\n","  [Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 1.154, -1.921], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=2, next_observation=array([0, 0], dtype=int32), action_prob=0.024393575, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 1.105, 10.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96553135, terminal=True)]),\n"," (-2e-05,\n","  230436,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  230438,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  211783,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 7.391, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.91044545, terminal=True)]),\n"," (-2e-05,\n","  221128,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  209464,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.295, -3.666], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9166206, terminal=True)]),\n"," (-2e-05,\n","  210231,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  219572,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  232777,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  221889,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  218016,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  229670,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  231985,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  234324,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  220345,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  232769,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  233542,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  217233,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  226564,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  236662,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  232005,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  224226,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  220340,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  222676,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  210224,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.879, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9726625, terminal=True)]),\n"," (-2e-05,\n","  222680,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  218786,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  218022,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  223459,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  218009,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  221137,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  230455,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  224999,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  225782,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  231213,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  220334,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  225780,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  235088,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  235869,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  221114,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  214903,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  229675,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  229662,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  222682,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  214125,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  236650,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  227341,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  228907,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  230451,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  229664,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  235880,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-0.0,\n","  16194,\n","  [Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 7.58 , -2.983], dtype=float32), value_vec=array([ 1.858, -1.   ], dtype=float32), horizon=3, next_observation=array([0, 1], dtype=int32), action_prob=0.17611128, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 7.897, -2.017], dtype=float32), value_vec=array([1.858, 0.   ], dtype=float32), horizon=2, next_observation=array([1, 1], dtype=int32), action_prob=0.24329172, terminal=False),\n","   Transition(observation=array([1, 1], dtype=int32), action=1, reward=array([ 8.2, -1. ], dtype=float32), return_=array([ 8.2, -1. ], dtype=float32), value_vec=array([1.858, 1.   ], dtype=float32), horizon=1, next_observation=array([2, 1], dtype=int32), action_prob=0.3048231, terminal=True)]),\n"," (-2e-05,\n","  234322,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  232770,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  223462,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  227325,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.951, -3.177], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9016095, terminal=True)]),\n"," (-2e-05,\n","  235093,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-0.0,\n","  162825,\n","  [Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 1.314, -2.21 ], dtype=float32), value_vec=array([3.873, 9.529], dtype=float32), horizon=2, next_observation=array([0, 0], dtype=int32), action_prob=0.048984807, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 3.873, 10.529], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9383384, terminal=True)]),\n"," (-2e-05,\n","  232779,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  229663,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  228906,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -27.659], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9413045, terminal=True)]),\n"," (-2e-05,\n","  233557,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  236652,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  228123,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([18.534, -8.187], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8750471, terminal=True)]),\n"," (-2e-05,\n","  226569,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  218787,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  214900,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.868, -3.782], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.85699284, terminal=True)]),\n"," (-2e-05,\n","  233551,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  231224,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  226560,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  235087,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  232004,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  221888,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  235105,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  235888,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  225787,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  235108,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  230448,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  218783,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  225778,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  219573,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  234332,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  232774,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  235101,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  221899,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  230444,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  219558,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  233545,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  230434,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  230433,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  235096,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  230449,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  226561,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  232763,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  215675,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  229666,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  231996,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  221115,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.18 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.94219685, terminal=True)]),\n"," (-2e-05,\n","  230450,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  229667,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  232778,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  229668,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  235111,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  230441,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  226563,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  220360,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.78 , -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8805742, terminal=True)]),\n"," (-2e-05,\n","  229669,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  231998,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  225016,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  231212,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  232764,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  230446,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  225000,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  230443,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  230458,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  225790,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  225008,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 0.501], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90910536, terminal=True)]),\n"," (-2e-05,\n","  224217,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  231220,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  230435,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  229676,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  230437,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-0.0,\n","  49136,\n","  [Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.665, -4.389], dtype=float32), value_vec=array([13.988, -4.125], dtype=float32), horizon=4, next_observation=array([0, 1], dtype=int32), action_prob=0.008384, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.506, -3.222], dtype=float32), value_vec=array([13.988, -3.125], dtype=float32), horizon=3, next_observation=array([0, 1], dtype=int32), action_prob=0.6919917, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.346, -2.12 ], dtype=float32), value_vec=array([13.988, -2.125], dtype=float32), horizon=2, next_observation=array([1, 1], dtype=int32), action_prob=0.02202925, terminal=False),\n","   Transition(observation=array([1, 1], dtype=int32), action=1, reward=array([ 8.2, -1. ], dtype=float32), return_=array([ 8.2, -1. ], dtype=float32), value_vec=array([13.988, -1.125], dtype=float32), horizon=1, next_observation=array([2, 1], dtype=int32), action_prob=0.7237675, terminal=True)]),\n"," (-2e-05,\n","  230440,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  230442,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  236664,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  233541,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  229678,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  229674,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  229679,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  230447,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  229671,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-2e-05,\n","  229672,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([0.7  , 1.513], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.956517, terminal=True)]),\n"," (-0.0,\n","  3935,\n","  [Transition(observation=array([0, 0], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 14., -11.], dtype=float32), value_vec=array([0., 0.]), horizon=11, next_observation=array([0, 0], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 14., -10.], dtype=float32), value_vec=array([0., 0.]), horizon=10, next_observation=array([0, 0], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([14., -9.], dtype=float32), value_vec=array([0., 0.]), horizon=9, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([14., -8.], dtype=float32), value_vec=array([0., 0.]), horizon=8, next_observation=array([0, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 2], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([14., -7.], dtype=float32), value_vec=array([0., 0.]), horizon=7, next_observation=array([1, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 2], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([14., -6.], dtype=float32), value_vec=array([0., 0.]), horizon=6, next_observation=array([1, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 3], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([14., -5.], dtype=float32), value_vec=array([0., 0.]), horizon=5, next_observation=array([2, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 3], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([14., -4.], dtype=float32), value_vec=array([0., 0.]), horizon=4, next_observation=array([2, 4], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 4], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([14., -3.], dtype=float32), value_vec=array([0., 0.]), horizon=3, next_observation=array([2, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 3], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([14., -2.], dtype=float32), value_vec=array([0., 0.]), horizon=2, next_observation=array([3, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 3], dtype=int32), action=1, reward=array([14., -1.], dtype=float32), return_=array([14., -1.], dtype=float32), value_vec=array([0., 0.]), horizon=1, next_observation=array([4, 3], dtype=int32), action_prob=0.25, terminal=True)]),\n"," (-2e-05,\n","  217229,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  226558,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  236669,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  218779,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  221896,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  234321,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  223441,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.628, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9319073, terminal=True)]),\n"," (-2e-05,\n","  235879,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  226557,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  236657,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  214114,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  231211,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  231988,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  214118,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.764, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96704805, terminal=True)]),\n"," (-2e-05,\n","  234312,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  221895,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-0.0,\n","  4030,\n","  [Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -40. ], dtype=float32), value_vec=array([0., 0.]), horizon=40, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -39. ], dtype=float32), value_vec=array([0., 0.]), horizon=39, next_observation=array([0, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 2], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -38. ], dtype=float32), value_vec=array([0., 0.]), horizon=38, next_observation=array([0, 1], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -37. ], dtype=float32), value_vec=array([0., 0.]), horizon=37, next_observation=array([0, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 2], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -36. ], dtype=float32), value_vec=array([0., 0.]), horizon=36, next_observation=array([0, 2], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 2], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -35. ], dtype=float32), value_vec=array([0., 0.]), horizon=35, next_observation=array([0, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 3], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -34. ], dtype=float32), value_vec=array([0., 0.]), horizon=34, next_observation=array([0, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 3], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -33. ], dtype=float32), value_vec=array([0., 0.]), horizon=33, next_observation=array([1, 3], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 3], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -32. ], dtype=float32), value_vec=array([0., 0.]), horizon=32, next_observation=array([1, 4], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 4], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -31. ], dtype=float32), value_vec=array([0., 0.]), horizon=31, next_observation=array([1, 5], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 5], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -30. ], dtype=float32), value_vec=array([0., 0.]), horizon=30, next_observation=array([1, 6], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 6], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -29. ], dtype=float32), value_vec=array([0., 0.]), horizon=29, next_observation=array([1, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 7], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -28. ], dtype=float32), value_vec=array([0., 0.]), horizon=28, next_observation=array([2, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 7], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -27. ], dtype=float32), value_vec=array([0., 0.]), horizon=27, next_observation=array([2, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 8], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -26. ], dtype=float32), value_vec=array([0., 0.]), horizon=26, next_observation=array([2, 7], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 7], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -25. ], dtype=float32), value_vec=array([0., 0.]), horizon=25, next_observation=array([2, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 8], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -24. ], dtype=float32), value_vec=array([0., 0.]), horizon=24, next_observation=array([2, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 9], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -23. ], dtype=float32), value_vec=array([0., 0.]), horizon=23, next_observation=array([1, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 9], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -22. ], dtype=float32), value_vec=array([0., 0.]), horizon=22, next_observation=array([0, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 9], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -21. ], dtype=float32), value_vec=array([0., 0.]), horizon=21, next_observation=array([ 0, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 0, 10], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -20. ], dtype=float32), value_vec=array([0., 0.]), horizon=20, next_observation=array([0, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 9], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -19. ], dtype=float32), value_vec=array([0., 0.]), horizon=19, next_observation=array([0, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([0, 9], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -18. ], dtype=float32), value_vec=array([0., 0.]), horizon=18, next_observation=array([1, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([1, 9], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -17. ], dtype=float32), value_vec=array([0., 0.]), horizon=17, next_observation=array([2, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 9], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -16. ], dtype=float32), value_vec=array([0., 0.]), horizon=16, next_observation=array([2, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -15. ], dtype=float32), value_vec=array([0., 0.]), horizon=15, next_observation=array([3, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 8], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -14. ], dtype=float32), value_vec=array([0., 0.]), horizon=14, next_observation=array([3, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 9], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -13. ], dtype=float32), value_vec=array([0., 0.]), horizon=13, next_observation=array([2, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([2, 9], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -12. ], dtype=float32), value_vec=array([0., 0.]), horizon=12, next_observation=array([3, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 9], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -11. ], dtype=float32), value_vec=array([0., 0.]), horizon=11, next_observation=array([ 3, 10], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([ 3, 10], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 22.4, -10. ], dtype=float32), value_vec=array([0., 0.]), horizon=10, next_observation=array([3, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 9], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([22.4, -9. ], dtype=float32), value_vec=array([0., 0.]), horizon=9, next_observation=array([4, 9], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([4, 9], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([22.4, -8. ], dtype=float32), value_vec=array([0., 0.]), horizon=8, next_observation=array([4, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([4, 8], dtype=int32), action=0, reward=array([ 0., -1.], dtype=float32), return_=array([22.4, -7. ], dtype=float32), value_vec=array([0., 0.]), horizon=7, next_observation=array([3, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([3, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([22.4, -6. ], dtype=float32), value_vec=array([0., 0.]), horizon=6, next_observation=array([4, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([4, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([22.4, -5. ], dtype=float32), value_vec=array([0., 0.]), horizon=5, next_observation=array([5, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([5, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([22.4, -4. ], dtype=float32), value_vec=array([0., 0.]), horizon=4, next_observation=array([6, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([6, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([22.4, -3. ], dtype=float32), value_vec=array([0., 0.]), horizon=3, next_observation=array([7, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([7, 8], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([22.4, -2. ], dtype=float32), value_vec=array([0., 0.]), horizon=2, next_observation=array([8, 8], dtype=int32), action_prob=0.25, terminal=False),\n","   Transition(observation=array([8, 8], dtype=int32), action=1, reward=array([22.4, -1. ], dtype=float32), return_=array([22.4, -1. ], dtype=float32), value_vec=array([0., 0.]), horizon=1, next_observation=array([9, 8], dtype=int32), action_prob=0.25, terminal=True)]),\n"," (-2e-05,\n","  218773,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  218789,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  232760,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  234313,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  236655,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  218784,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  224227,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 5.148, -1.   ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8884199, terminal=True)]),\n"," (-2e-05,\n","  233540,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  231219,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  234335,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  218006,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  221897,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  231218,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  226555,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  231999,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  236666,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  218781,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  236649,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  231995,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  236645,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  236665,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  233560,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  235889,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  235868,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  235112,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  222664,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  232007,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  230456,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  216457,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  219559,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  226568,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  231210,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  235881,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  226559,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (1,\n","  237420,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 13.208, -13.384], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90985554, terminal=True)]),\n"," (-2e-05,\n","  232782,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  231214,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  226562,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  232784,\n","  [Transition(observation=array([0, 0], dtype=int32), action=2, reward=array([ 0., -1.], dtype=float32), return_=array([ 1.154, -1.921], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=2, next_observation=array([0, 0], dtype=int32), action_prob=0.024393575, terminal=False),\n","   Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 1.105, 10.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96553135, terminal=True)]),\n"," (-2e-05,\n","  234317,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  222681,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.587, -20.812], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9161305, terminal=True)]),\n"," (-2e-05,\n","  232781,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  231232,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  231994,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  217219,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 25.438, -31.938], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.87492037, terminal=True)]),\n"," (-2e-05,\n","  225794,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  230457,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.575, -17.605], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8985248, terminal=True)]),\n"," (-2e-05,\n","  218788,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 16.759, -17.435], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9126587, terminal=True)]),\n"," (-2e-05,\n","  207132,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 24.802, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.90382713, terminal=True)]),\n"," (-2e-05,\n","  231223,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  213359,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 21.788, -26.646], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96867424, terminal=True)]),\n"," (-2e-05,\n","  231230,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  219564,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 23.975, -22.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8648577, terminal=True)]),\n"," (-2e-05,\n","  218005,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.924, -26.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96682733, terminal=True)]),\n"," (-2e-05,\n","  231997,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  231989,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  231227,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  232773,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-0.0,\n","  119965,\n","  [Transition(observation=array([0, 0], dtype=int32), action=3, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.541, -3.468], dtype=float32), value_vec=array([3.641, 8.416], dtype=float32), horizon=3, next_observation=array([0, 1], dtype=int32), action_prob=0.02921023, terminal=False),\n","   Transition(observation=array([0, 1], dtype=int32), action=1, reward=array([ 0., -1.], dtype=float32), return_=array([ 8.387, -2.172], dtype=float32), value_vec=array([3.641, 9.416], dtype=float32), horizon=2, next_observation=array([1, 1], dtype=int32), action_prob=0.6755536, terminal=False),\n","   Transition(observation=array([1, 1], dtype=int32), action=1, reward=array([ 8.2, -1. ], dtype=float32), return_=array([ 8.2, -1. ], dtype=float32), value_vec=array([ 3.641, 10.416], dtype=float32), horizon=1, next_observation=array([2, 1], dtype=int32), action_prob=0.8475457, terminal=True)]),\n"," (-2e-05,\n","  235099,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  235089,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  225798,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  208673,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 17.433, -16.298], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97268695, terminal=True)]),\n"," (-2e-05,\n","  226552,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  231992,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  233552,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  233555,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -24.109], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97262037, terminal=True)]),\n"," (-2e-05,\n","  231990,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  235867,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 9.631, -0.453], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9201665, terminal=True)]),\n"," (-2e-05,\n","  232762,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([1.105, 9.574], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96856385, terminal=True)]),\n"," (-2e-05,\n","  235095,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," (-2e-05,\n","  225799,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  232000,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  234334,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  231987,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  232008,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.667, -5.885], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9375878, terminal=True)]),\n"," (-2e-05,\n","  226551,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  236644,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.181, -20.835], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.95253927, terminal=True)]),\n"," (-2e-05,\n","  226553,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([4.301, 7.929], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.97330654, terminal=True)]),\n"," (-2e-05,\n","  234336,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  215678,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.305, -14.708], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.89025617, terminal=True)]),\n"," (-2e-05,\n","  221894,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  231215,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  231228,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 18.379, -15.644], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.958491, terminal=True)]),\n"," (-2e-05,\n","  221893,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 26.294, -38.125], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96289563, terminal=True)]),\n"," (-2e-05,\n","  225797,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 8.129, -3.332], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.86808985, terminal=True)]),\n"," (-2e-05,\n","  216461,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([11.631, -5.88 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.8410723, terminal=True)]),\n"," (-2e-05,\n","  234314,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 20.928, -20.953], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.9544352, terminal=True)]),\n"," (-2e-05,\n","  235090,\n","  [Transition(observation=array([0, 0], dtype=int32), action=1, reward=array([ 0.7, -1. ], dtype=float32), return_=array([ 0.7, -1. ], dtype=float32), value_vec=array([ 15.061, -16.05 ], dtype=float32), horizon=1, next_observation=array([1, 0], dtype=int32), action_prob=0.96015847, terminal=True)]),\n"," ...]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# Training Notes\n","- Most episodes in the ER only reach the first reward:\n","  - ER buffer is constructed such that new episodes are always added\n","  - This removes episodes by:\n","    1. Duplicates\n","    2. Distance metric (L2 + crowding)\n","    3. Oldest first\n","  - better returns are achieved as better PF returns are added to the PF\n","\n","- buffer size, batch size and num expl episodes are important choices:\n","  - Num expl episodes needs to add enough episodes for them to be of significance during the next training iteration(s)\n","  - If num_exl is too large (and buffer size too small) then exploration episodes can overwrite episodes with good returns!\n","  - The smaller the batch size, the more these episodes have impact on training => faster convergence (depending on environment0\n","  - Larger buffer size means less chance of these exploration episodes to be used for training in the next timestep. A sufficient size is needed to ensure enough points are in te buffer for computing each point in the pf (at least batch_size*num_pf_points, but pref. more)\n","  - Preferably small batch size (16/32/64) and large buffer (1024/2048) depending on problem size\n","  - Depending on buffer size, pick sufficiently large number of exploration episodes to increase convergence speed\n","\n","Idea:\n","- In order to improve the PF over time, average returns (from s0) must improve\n","- We need sufficient 'better' trajectories (at least batch_size) for this average to improve\n","- Take batches of (s,a) instead of only over state. This implies that taking similar actions in similar states leads to similar polices, which in term helps with convergence\n","- Using such batches could also solve loss/gradient issues!\n","- This complies with using this model for stochastic transitions, as we want averages over state action pairs\n","- This implies that we learn deterministic policies\n","\n","Questions:\n","- Policy explorations improved drastically after using tanh inbetween hidden layers\n","- Value estimates are more accurate when using tanh\n","- Weighting losses using IS ratio should help because data is very off-policy compared to single-objective RL. => policy evaluation is still poor\n","  - High-valued returns are only achieved when randomness is used in the policy\n","- buffer returns get better, but eval returns are bad => all policies have high probability of instantly going down...\n","\n","TODO:\n","- After policy evaluation it is clear that the agent often does not reach a terminal state => it learns to make cycles and uses these bootstrapped estimates to get its rewards...\n","  - weight policy loss so off-policy actions contribute less => less-likely to learn wrong actions by off policy learning... upon policy eval, the policies result in the first reward only\n","  - Experiment with Beta: slightly larger values result in better policy eval!\n","\n","- Try to balance actor and critic updates:\n","  - In AWR, the actor is updated more than the critic. This is because the critic is only used to compute the advantage weights, and not for guiding the policy gradients themselves.\n","  - AWR remains stable without any target network for the critic for this same reason. In our case, value estimates are used for computing the TD(lambda) return (as in AWR). But this return is then used as conditioning for both the actor and critic.\n","- The POPF function behaves similar to the value function and is also trained using V: It might show similar overestimation issues!\n","\n","- PF contains 'intermediate' returns: averages of different solutions which are non-dominated by themselves, but are not a distinct solution when evaluated.\n","  - This is problem specific...\n","  - Eg. the 3 returns next to each other are very close together (thus have a low crowding distance). Expected returns between 0.7 and 8.3 are in the PF, but not achievable (unless by stochastic policy). This is because crowding distance is higher than for the others."],"metadata":{"id":"e5LPy1SReVGw"}}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOsp5+nAfUfZdTm2E3LyD7i"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}